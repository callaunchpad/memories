{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import decorators\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data file\n",
    "# Give the location of the file \n",
    "\n",
    "df = pd.read_excel(r'data/data.xlsx', sheet_name='reduced totals')\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 80\n",
      "320 80\n"
     ]
    }
   ],
   "source": [
    "## LOADING IN DATASETS\n",
    "\n",
    "dataset = Path.cwd().joinpath(\"SongEmotionDataset\")\n",
    "dataset = Path.cwd().joinpath(\"data\") # for csua\n",
    "\n",
    "#emotion labels\n",
    "label_loc = dataset.joinpath(\"data.xlsx\")\n",
    "wb = xlrd.open_workbook(label_loc) \n",
    "sheet = wb.sheet_by_index(1)\n",
    "\n",
    "#emotion arr\n",
    "emotions = [\"amazement\", \"solemnity\", \"tenderness\", \"nostalgia\", \"calmness\", \"power\", \"joyful activation\", \"tension\", \"sadness\"]\n",
    "\n",
    "train_song = []\n",
    "test_song = []\n",
    "train_emotion = []\n",
    "test_emotion = []\n",
    "\n",
    "for i in range(1, 401):\n",
    "    count_total = sheet.cell_value(i, 11)\n",
    "    if i % 5 == 0:\n",
    "        test_song.append(dataset.joinpath(\"{}.mp3\".format(i)))\n",
    "        emotion_arr = []\n",
    "        for j in range(5):\n",
    "            emotion_arr.append(sheet.cell_value(i, 2 + j) / count_total) #percentage of total\n",
    "        test_emotion.append(torch.tensor(emotion_arr, device=device).float())\n",
    "    else:\n",
    "        train_song.append(dataset.joinpath(\"{}.mp3\".format(i)))\n",
    "        emotion_arr = []\n",
    "        for j in range(9):\n",
    "            emotion_arr.append(sheet.cell_value(i, 2 + j) / count_total) #percentage of total\n",
    "        train_emotion.append(torch.tensor(emotion_arr))\n",
    "\n",
    "print(len(train_song), len(test_song))\n",
    "print(len(train_emotion), len(test_emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.0700, 0.1600, 0.1000, 0.1400, 0.3000, 0.0100, 0.0400, 0.0300, 0.1500]),\n",
       " tensor([0.0538, 0.0860, 0.2151, 0.1720, 0.3763, 0.0215, 0.0108, 0.0108, 0.0538]),\n",
       " tensor([0.0879, 0.1758, 0.0659, 0.0879, 0.0330, 0.1429, 0.2088, 0.1209, 0.0769]),\n",
       " tensor([0.0543, 0.0652, 0.2391, 0.2065, 0.3478, 0.0109, 0.0000, 0.0109, 0.0652]),\n",
       " tensor([0.0549, 0.1099, 0.1099, 0.1538, 0.2857, 0.0330, 0.1209, 0.0659, 0.0659]),\n",
       " tensor([0.1739, 0.0435, 0.0761, 0.0435, 0.0543, 0.1087, 0.4130, 0.0761, 0.0109]),\n",
       " tensor([0.0430, 0.1398, 0.1613, 0.1505, 0.2366, 0.0215, 0.0968, 0.0753, 0.0753]),\n",
       " tensor([0.0543, 0.1304, 0.1522, 0.1957, 0.2283, 0.0217, 0.0326, 0.0109, 0.1739]),\n",
       " tensor([0.0220, 0.1538, 0.1209, 0.1978, 0.1868, 0.0220, 0.0330, 0.0659, 0.1978]),\n",
       " tensor([0.1758, 0.0330, 0.0879, 0.0879, 0.0879, 0.0440, 0.4176, 0.0440, 0.0220]),\n",
       " tensor([0.0110, 0.1648, 0.0769, 0.2088, 0.1978, 0.0769, 0.0110, 0.1209, 0.1319]),\n",
       " tensor([0.0659, 0.1099, 0.1648, 0.1758, 0.2088, 0.0440, 0.0769, 0.0879, 0.0659]),\n",
       " tensor([0.0440, 0.1319, 0.0220, 0.0220, 0.0110, 0.3407, 0.0549, 0.3077, 0.0659]),\n",
       " tensor([0.0430, 0.0753, 0.2688, 0.2043, 0.3011, 0.0000, 0.0000, 0.0215, 0.0860]),\n",
       " tensor([0.2088, 0.0989, 0.0330, 0.0659, 0.0659, 0.0549, 0.4505, 0.0220, 0.0000]),\n",
       " tensor([0.0549, 0.1758, 0.1758, 0.1429, 0.2418, 0.0220, 0.0220, 0.0549, 0.1099]),\n",
       " tensor([0.0769, 0.1099, 0.1978, 0.1319, 0.3077, 0.0110, 0.0989, 0.0220, 0.0440]),\n",
       " tensor([0.0989, 0.1319, 0.2198, 0.0549, 0.1978, 0.0330, 0.1868, 0.0440, 0.0330]),\n",
       " tensor([0.0769, 0.2418, 0.0220, 0.0440, 0.0220, 0.1868, 0.3077, 0.0549, 0.0440]),\n",
       " tensor([0.0543, 0.1196, 0.0000, 0.0000, 0.0435, 0.2283, 0.2935, 0.2174, 0.0435]),\n",
       " tensor([0.1304, 0.1304, 0.0109, 0.0978, 0.0109, 0.1630, 0.3152, 0.1087, 0.0326]),\n",
       " tensor([0.0440, 0.3077, 0.0000, 0.0220, 0.0110, 0.3297, 0.0220, 0.1758, 0.0879]),\n",
       " tensor([0.1720, 0.0430, 0.1398, 0.0323, 0.2258, 0.0000, 0.3656, 0.0215, 0.0000]),\n",
       " tensor([0.0753, 0.1398, 0.1398, 0.1398, 0.2151, 0.0108, 0.0645, 0.0430, 0.1720]),\n",
       " tensor([0.0435, 0.0978, 0.1413, 0.2609, 0.2500, 0.0217, 0.0109, 0.0435, 0.1304]),\n",
       " tensor([0.0385, 0.1282, 0.1154, 0.2051, 0.2436, 0.0128, 0.0641, 0.0256, 0.1667]),\n",
       " tensor([0.0000, 0.0746, 0.1791, 0.1791, 0.3433, 0.0000, 0.0299, 0.0299, 0.1642]),\n",
       " tensor([0.1429, 0.0714, 0.0714, 0.0714, 0.1667, 0.0238, 0.3810, 0.0476, 0.0238]),\n",
       " tensor([0.0625, 0.0625, 0.1562, 0.1875, 0.2812, 0.0625, 0.0000, 0.0938, 0.0938]),\n",
       " tensor([0.0811, 0.1081, 0.2162, 0.1622, 0.1622, 0.0270, 0.0000, 0.1081, 0.1351]),\n",
       " tensor([0.0303, 0.1212, 0.1515, 0.1818, 0.2727, 0.0000, 0.0303, 0.0303, 0.1818]),\n",
       " tensor([0.2564, 0.1282, 0.0000, 0.0000, 0.0000, 0.2308, 0.3077, 0.0769, 0.0000]),\n",
       " tensor([0.0857, 0.2000, 0.1143, 0.1714, 0.1714, 0.0286, 0.0857, 0.0571, 0.0857]),\n",
       " tensor([0.1000, 0.1000, 0.1333, 0.1000, 0.3667, 0.0667, 0.0000, 0.0667, 0.0667]),\n",
       " tensor([0.1212, 0.1212, 0.0909, 0.1212, 0.0303, 0.0909, 0.1515, 0.1212, 0.1515]),\n",
       " tensor([0.0882, 0.1765, 0.1176, 0.0882, 0.2353, 0.0588, 0.1176, 0.0294, 0.0882]),\n",
       " tensor([0.0938, 0.0625, 0.2500, 0.2188, 0.2812, 0.0000, 0.0312, 0.0000, 0.0625]),\n",
       " tensor([0.0263, 0.0789, 0.1053, 0.2105, 0.1842, 0.0263, 0.0263, 0.0526, 0.2895]),\n",
       " tensor([0.0294, 0.2353, 0.0294, 0.1765, 0.1176, 0.0294, 0.0588, 0.1765, 0.1471]),\n",
       " tensor([0.0000, 0.2439, 0.0488, 0.0488, 0.0488, 0.1220, 0.0244, 0.1951, 0.2683]),\n",
       " tensor([0.0556, 0.0833, 0.1111, 0.3333, 0.1667, 0.0000, 0.0000, 0.0556, 0.1944]),\n",
       " tensor([0.1176, 0.1765, 0.0294, 0.0294, 0.0294, 0.1176, 0.2647, 0.2059, 0.0294]),\n",
       " tensor([0.1053, 0.1579, 0.0000, 0.0789, 0.0000, 0.1316, 0.1579, 0.3158, 0.0526]),\n",
       " tensor([0.0732, 0.0732, 0.0732, 0.0000, 0.1951, 0.1220, 0.3659, 0.0488, 0.0488]),\n",
       " tensor([0.0833, 0.0833, 0.1667, 0.1389, 0.3611, 0.0278, 0.0556, 0.0000, 0.0833]),\n",
       " tensor([0.1081, 0.3243, 0.1081, 0.0541, 0.0541, 0.0270, 0.0270, 0.1081, 0.1892]),\n",
       " tensor([0.0270, 0.1622, 0.0541, 0.0811, 0.0541, 0.2162, 0.0811, 0.2162, 0.1081]),\n",
       " tensor([0.1143, 0.1143, 0.0000, 0.0571, 0.0000, 0.2286, 0.2857, 0.1429, 0.0571]),\n",
       " tensor([0.0968, 0.0968, 0.0000, 0.0968, 0.0968, 0.0323, 0.3226, 0.1935, 0.0645]),\n",
       " tensor([0.1034, 0.0000, 0.0690, 0.1379, 0.0000, 0.0690, 0.4483, 0.1724, 0.0000]),\n",
       " tensor([0.0303, 0.1515, 0.1212, 0.2121, 0.2424, 0.0000, 0.0000, 0.0909, 0.1515]),\n",
       " tensor([0.1481, 0.0370, 0.0370, 0.0370, 0.1481, 0.0741, 0.3704, 0.1481, 0.0000]),\n",
       " tensor([0.0769, 0.1538, 0.0000, 0.1154, 0.0385, 0.1154, 0.1538, 0.3077, 0.0385]),\n",
       " tensor([0.0968, 0.0968, 0.1613, 0.0323, 0.2581, 0.0645, 0.1290, 0.1290, 0.0323]),\n",
       " tensor([0.0000, 0.1143, 0.1429, 0.2286, 0.2857, 0.0286, 0.0286, 0.0571, 0.1143]),\n",
       " tensor([0.0215, 0.0860, 0.2903, 0.2473, 0.2688, 0.0215, 0.0323, 0.0323, 0.0000]),\n",
       " tensor([0.0938, 0.1562, 0.0312, 0.0938, 0.1250, 0.0938, 0.3438, 0.0625, 0.0000]),\n",
       " tensor([0.1282, 0.1538, 0.0000, 0.0769, 0.1538, 0.1026, 0.1538, 0.1538, 0.0769]),\n",
       " tensor([0.1111, 0.1111, 0.1111, 0.2222, 0.1852, 0.0000, 0.1111, 0.1481, 0.0000]),\n",
       " tensor([0.1351, 0.1081, 0.0270, 0.0811, 0.1081, 0.1081, 0.1622, 0.2162, 0.0541]),\n",
       " tensor([0.0000, 0.2188, 0.0000, 0.0938, 0.0625, 0.0625, 0.1875, 0.2500, 0.1250]),\n",
       " tensor([0.0303, 0.0606, 0.2121, 0.1818, 0.2424, 0.0303, 0.1515, 0.0909, 0.0000]),\n",
       " tensor([0.0606, 0.0909, 0.0606, 0.0909, 0.0303, 0.1212, 0.3333, 0.2121, 0.0000]),\n",
       " tensor([0.0909, 0.0606, 0.0303, 0.1515, 0.1212, 0.0909, 0.3030, 0.0909, 0.0606]),\n",
       " tensor([0.0625, 0.1562, 0.0312, 0.0000, 0.0938, 0.1562, 0.3750, 0.1250, 0.0000]),\n",
       " tensor([0.0286, 0.0286, 0.2286, 0.2571, 0.3714, 0.0000, 0.0000, 0.0000, 0.0857]),\n",
       " tensor([0.0769, 0.0513, 0.1026, 0.2308, 0.0769, 0.0256, 0.1795, 0.0769, 0.1795]),\n",
       " tensor([0.0270, 0.2432, 0.1081, 0.1892, 0.2162, 0.0270, 0.0541, 0.0541, 0.0811]),\n",
       " tensor([0.0857, 0.1714, 0.0286, 0.0857, 0.1429, 0.1143, 0.0857, 0.2000, 0.0857]),\n",
       " tensor([0.0312, 0.1250, 0.1562, 0.2188, 0.2812, 0.0000, 0.0000, 0.0000, 0.1875]),\n",
       " tensor([0.1212, 0.0303, 0.0606, 0.0909, 0.0000, 0.1212, 0.2424, 0.2424, 0.0909]),\n",
       " tensor([0.0000, 0.0333, 0.2333, 0.2333, 0.4000, 0.0000, 0.0333, 0.0000, 0.0667]),\n",
       " tensor([0.0000, 0.2121, 0.0909, 0.1515, 0.1818, 0.0303, 0.0000, 0.0303, 0.3030]),\n",
       " tensor([0.0625, 0.2188, 0.0938, 0.1875, 0.2812, 0.0000, 0.0625, 0.0312, 0.0625]),\n",
       " tensor([0.0625, 0.0000, 0.1875, 0.1250, 0.4688, 0.0000, 0.0938, 0.0000, 0.0625]),\n",
       " tensor([0.1389, 0.2778, 0.0000, 0.0278, 0.1667, 0.0556, 0.1389, 0.1111, 0.0833]),\n",
       " tensor([0.0312, 0.0938, 0.1875, 0.1562, 0.2500, 0.0312, 0.1875, 0.0312, 0.0312]),\n",
       " tensor([0.0690, 0.2759, 0.0345, 0.1034, 0.1379, 0.0000, 0.0000, 0.1724, 0.2069]),\n",
       " tensor([0.0286, 0.2000, 0.1143, 0.1714, 0.2857, 0.0000, 0.0000, 0.0286, 0.1714]),\n",
       " tensor([0.0513, 0.0513, 0.1795, 0.1026, 0.3846, 0.0513, 0.0769, 0.0256, 0.0769]),\n",
       " tensor([0.0108, 0.1398, 0.0968, 0.1613, 0.0538, 0.1398, 0.1075, 0.1290, 0.1613]),\n",
       " tensor([0.0667, 0.0222, 0.2000, 0.3333, 0.2000, 0.0000, 0.1111, 0.0222, 0.0444]),\n",
       " tensor([0.0562, 0.0337, 0.0337, 0.0899, 0.0899, 0.2472, 0.2697, 0.1348, 0.0449]),\n",
       " tensor([0.1023, 0.1136, 0.1477, 0.2386, 0.1250, 0.0227, 0.0682, 0.0795, 0.1023]),\n",
       " tensor([0.0440, 0.0440, 0.1429, 0.2418, 0.1978, 0.0220, 0.0330, 0.0330, 0.2418]),\n",
       " tensor([0.1236, 0.1573, 0.0899, 0.1124, 0.1685, 0.0562, 0.1348, 0.0787, 0.0787]),\n",
       " tensor([0.0667, 0.1444, 0.0556, 0.1778, 0.1444, 0.1333, 0.0222, 0.1556, 0.1000]),\n",
       " tensor([0.1011, 0.0562, 0.0337, 0.0787, 0.0449, 0.2360, 0.2360, 0.1798, 0.0337]),\n",
       " tensor([0.1319, 0.0330, 0.0110, 0.0549, 0.0549, 0.2088, 0.3846, 0.0769, 0.0440]),\n",
       " tensor([0.0778, 0.1111, 0.0222, 0.1778, 0.1667, 0.1444, 0.0444, 0.1667, 0.0889]),\n",
       " tensor([0.0220, 0.0549, 0.2308, 0.2308, 0.2308, 0.0000, 0.0110, 0.0330, 0.1868]),\n",
       " tensor([0.0330, 0.1538, 0.0220, 0.1648, 0.0989, 0.2088, 0.0549, 0.1538, 0.1099]),\n",
       " tensor([0.0444, 0.1000, 0.1333, 0.2000, 0.1333, 0.1333, 0.1111, 0.0889, 0.0556]),\n",
       " tensor([0.0341, 0.0795, 0.1705, 0.2045, 0.2955, 0.0000, 0.0341, 0.0568, 0.1250]),\n",
       " tensor([0.0375, 0.0625, 0.2750, 0.2500, 0.2500, 0.0000, 0.0125, 0.0125, 0.1000]),\n",
       " tensor([0.1842, 0.1053, 0.0526, 0.0263, 0.0000, 0.2105, 0.2895, 0.1316, 0.0000]),\n",
       " tensor([0.1034, 0.0345, 0.0000, 0.0000, 0.0000, 0.3448, 0.1034, 0.3103, 0.1034]),\n",
       " tensor([0.0857, 0.0571, 0.3143, 0.2000, 0.1429, 0.0857, 0.0286, 0.0571, 0.0286]),\n",
       " tensor([0.0417, 0.0000, 0.0000, 0.0833, 0.0000, 0.1667, 0.5417, 0.1250, 0.0417]),\n",
       " tensor([0.0909, 0.0455, 0.0455, 0.1818, 0.1364, 0.0455, 0.0909, 0.1364, 0.2273]),\n",
       " tensor([0.0556, 0.1111, 0.0000, 0.0000, 0.0000, 0.1667, 0.5000, 0.1667, 0.0000]),\n",
       " tensor([0.0952, 0.0000, 0.0000, 0.1429, 0.0000, 0.0952, 0.2381, 0.3333, 0.0952]),\n",
       " tensor([0.1724, 0.0690, 0.0000, 0.1724, 0.0345, 0.1379, 0.3103, 0.0690, 0.0345]),\n",
       " tensor([0.1481, 0.0741, 0.0741, 0.0370, 0.0741, 0.2222, 0.2963, 0.0741, 0.0000]),\n",
       " tensor([0.0000, 0.0714, 0.0714, 0.1429, 0.0357, 0.0714, 0.0000, 0.1786, 0.4286]),\n",
       " tensor([0.0833, 0.0000, 0.1250, 0.2083, 0.0833, 0.0417, 0.2500, 0.0833, 0.1250]),\n",
       " tensor([0.0345, 0.1034, 0.1379, 0.1724, 0.3103, 0.0690, 0.0000, 0.0000, 0.1724]),\n",
       " tensor([0.0000, 0.1111, 0.2222, 0.1481, 0.1852, 0.0741, 0.0370, 0.0741, 0.1481]),\n",
       " tensor([0.0370, 0.0741, 0.0370, 0.1111, 0.0370, 0.2593, 0.1852, 0.2222, 0.0370]),\n",
       " tensor([0.0800, 0.0000, 0.0400, 0.0800, 0.0000, 0.2800, 0.2800, 0.2000, 0.0400]),\n",
       " tensor([0.0833, 0.0000, 0.0000, 0.0417, 0.0833, 0.2917, 0.3750, 0.0833, 0.0417]),\n",
       " tensor([0.0968, 0.0645, 0.0323, 0.1290, 0.0000, 0.3226, 0.0323, 0.1613, 0.1613]),\n",
       " tensor([0.0870, 0.0870, 0.0000, 0.1739, 0.0435, 0.1304, 0.0435, 0.1304, 0.3043]),\n",
       " tensor([0.0000, 0.1111, 0.0741, 0.1111, 0.1852, 0.0741, 0.0000, 0.1852, 0.2593]),\n",
       " tensor([0.0690, 0.1034, 0.0690, 0.1034, 0.2759, 0.1034, 0.1379, 0.0690, 0.0690]),\n",
       " tensor([0.1538, 0.0385, 0.0000, 0.0000, 0.0769, 0.1538, 0.3462, 0.2308, 0.0000]),\n",
       " tensor([0.0968, 0.1290, 0.1290, 0.1613, 0.1290, 0.0645, 0.0968, 0.0323, 0.1613]),\n",
       " tensor([0.0667, 0.0333, 0.0667, 0.2333, 0.2000, 0.0667, 0.1333, 0.0667, 0.1333]),\n",
       " tensor([0.2000, 0.0000, 0.0400, 0.1600, 0.1200, 0.1200, 0.2000, 0.1200, 0.0400]),\n",
       " tensor([0.0357, 0.0357, 0.1786, 0.2500, 0.3214, 0.0000, 0.0000, 0.0357, 0.1429]),\n",
       " tensor([0.0000, 0.0000, 0.1429, 0.2143, 0.1071, 0.1786, 0.2143, 0.0357, 0.1071]),\n",
       " tensor([0.0312, 0.1250, 0.0000, 0.1562, 0.0000, 0.3438, 0.0625, 0.1562, 0.1250]),\n",
       " tensor([0.0370, 0.0370, 0.0000, 0.3704, 0.1852, 0.0370, 0.0741, 0.0000, 0.2593]),\n",
       " tensor([0.0741, 0.0741, 0.0370, 0.1852, 0.1852, 0.0370, 0.1852, 0.0741, 0.1481]),\n",
       " tensor([0.1200, 0.0000, 0.0000, 0.0000, 0.0400, 0.2400, 0.5600, 0.0400, 0.0000]),\n",
       " tensor([0.0800, 0.1200, 0.0800, 0.1200, 0.1200, 0.0400, 0.1200, 0.1600, 0.1600]),\n",
       " tensor([0.1667, 0.1389, 0.0278, 0.1389, 0.1667, 0.0833, 0.1389, 0.0556, 0.0833]),\n",
       " tensor([0.1250, 0.0000, 0.1667, 0.2500, 0.1667, 0.0417, 0.0833, 0.1667, 0.0000]),\n",
       " tensor([0.0000, 0.0833, 0.0417, 0.0417, 0.0833, 0.1250, 0.0000, 0.5417, 0.0833]),\n",
       " tensor([0.0000, 0.0385, 0.0000, 0.1154, 0.0000, 0.3462, 0.2692, 0.1923, 0.0385]),\n",
       " tensor([0.0357, 0.0357, 0.1429, 0.2500, 0.0714, 0.1786, 0.1071, 0.1071, 0.0714]),\n",
       " tensor([0.0690, 0.0690, 0.2069, 0.2069, 0.1379, 0.0345, 0.0690, 0.0345, 0.1724]),\n",
       " tensor([0.1000, 0.0333, 0.1000, 0.3000, 0.1000, 0.1000, 0.1333, 0.0667, 0.0667]),\n",
       " tensor([0.1053, 0.0526, 0.1053, 0.1579, 0.1053, 0.0526, 0.2105, 0.1053, 0.1053]),\n",
       " tensor([0.0800, 0.0000, 0.0800, 0.3600, 0.2000, 0.0000, 0.0400, 0.0800, 0.1600]),\n",
       " tensor([0.1667, 0.0417, 0.0000, 0.0417, 0.0000, 0.2500, 0.3750, 0.1250, 0.0000]),\n",
       " tensor([0.0000, 0.1111, 0.0000, 0.0741, 0.0741, 0.2222, 0.1481, 0.2963, 0.0741]),\n",
       " tensor([0.1379, 0.0690, 0.1724, 0.2759, 0.1724, 0.0345, 0.1034, 0.0345, 0.0000]),\n",
       " tensor([0.1081, 0.0541, 0.0270, 0.1622, 0.1892, 0.1351, 0.2432, 0.0811, 0.0000]),\n",
       " tensor([0.0769, 0.0385, 0.0000, 0.0769, 0.0000, 0.3462, 0.1538, 0.1923, 0.1154]),\n",
       " tensor([0.0000, 0.0000, 0.1364, 0.1591, 0.1591, 0.0000, 0.0227, 0.0227, 0.5000]),\n",
       " tensor([0.0000, 0.0323, 0.1935, 0.1935, 0.2581, 0.0968, 0.0968, 0.0323, 0.0968]),\n",
       " tensor([0.1429, 0.0714, 0.1786, 0.1429, 0.2857, 0.0357, 0.0714, 0.0714, 0.0000]),\n",
       " tensor([0.0870, 0.0870, 0.0000, 0.1304, 0.0435, 0.0000, 0.4348, 0.1739, 0.0435]),\n",
       " tensor([0.0385, 0.0385, 0.1538, 0.0385, 0.1538, 0.1538, 0.3077, 0.1154, 0.0000]),\n",
       " tensor([0.0370, 0.0370, 0.2963, 0.1852, 0.2963, 0.0000, 0.0000, 0.0000, 0.1481]),\n",
       " tensor([0.0385, 0.0385, 0.1923, 0.2308, 0.2692, 0.0000, 0.0385, 0.0000, 0.1923]),\n",
       " tensor([0.0800, 0.0400, 0.1600, 0.2000, 0.3200, 0.0000, 0.0800, 0.1200, 0.0000]),\n",
       " tensor([0.1154, 0.0385, 0.1538, 0.1538, 0.0769, 0.1538, 0.1154, 0.0769, 0.1154]),\n",
       " tensor([0.0000, 0.1852, 0.1111, 0.1852, 0.2222, 0.0370, 0.0000, 0.0741, 0.1852]),\n",
       " tensor([0.0312, 0.0000, 0.2188, 0.2500, 0.0938, 0.0312, 0.0625, 0.0938, 0.2188]),\n",
       " tensor([0.0667, 0.0333, 0.2667, 0.0333, 0.1333, 0.0667, 0.2333, 0.1000, 0.0667]),\n",
       " tensor([0.0690, 0.1034, 0.2069, 0.2069, 0.2069, 0.0345, 0.0690, 0.0345, 0.0690]),\n",
       " tensor([0.0000, 0.0690, 0.2069, 0.2069, 0.2069, 0.0690, 0.1034, 0.0690, 0.0690]),\n",
       " tensor([0.0000, 0.0667, 0.2000, 0.2333, 0.2000, 0.0000, 0.0000, 0.0333, 0.2667]),\n",
       " tensor([0.0667, 0.0333, 0.1333, 0.1333, 0.1667, 0.1000, 0.2000, 0.0000, 0.1667]),\n",
       " tensor([0.1034, 0.0690, 0.0000, 0.2414, 0.2069, 0.0345, 0.1379, 0.0690, 0.1379]),\n",
       " tensor([0.0909, 0.0909, 0.0455, 0.0909, 0.0455, 0.1818, 0.2727, 0.1364, 0.0455]),\n",
       " tensor([0.1304, 0.0000, 0.0435, 0.0870, 0.0435, 0.2609, 0.4348, 0.0000, 0.0000]),\n",
       " tensor([0.1923, 0.0769, 0.0385, 0.1154, 0.0000, 0.3462, 0.1538, 0.0385, 0.0385]),\n",
       " tensor([0.0659, 0.0769, 0.0000, 0.0110, 0.0879, 0.1648, 0.2088, 0.3516, 0.0330]),\n",
       " tensor([0.0879, 0.0989, 0.0330, 0.0549, 0.2857, 0.0440, 0.2857, 0.1099, 0.0000]),\n",
       " tensor([0.0549, 0.2308, 0.0110, 0.0330, 0.0549, 0.2418, 0.0110, 0.2637, 0.0989]),\n",
       " tensor([0.0440, 0.1648, 0.0000, 0.0440, 0.0330, 0.2967, 0.0220, 0.3407, 0.0549]),\n",
       " tensor([0.0435, 0.0761, 0.0109, 0.0109, 0.0435, 0.1957, 0.3261, 0.2717, 0.0217]),\n",
       " tensor([0.0645, 0.0860, 0.0108, 0.0645, 0.1183, 0.0645, 0.2043, 0.3548, 0.0323]),\n",
       " tensor([0.0652, 0.1739, 0.0761, 0.0870, 0.2391, 0.0870, 0.0543, 0.1630, 0.0543]),\n",
       " tensor([0.0645, 0.0538, 0.0000, 0.0323, 0.0323, 0.1935, 0.3118, 0.3011, 0.0108]),\n",
       " tensor([0.0417, 0.0729, 0.0417, 0.0208, 0.1250, 0.1146, 0.1458, 0.3646, 0.0729]),\n",
       " tensor([0.0645, 0.1075, 0.0215, 0.0753, 0.1290, 0.2043, 0.2151, 0.1828, 0.0000]),\n",
       " tensor([0.0889, 0.0667, 0.0444, 0.1000, 0.2000, 0.0889, 0.2333, 0.1111, 0.0667]),\n",
       " tensor([0.0870, 0.0435, 0.0326, 0.0978, 0.0978, 0.0978, 0.3261, 0.1739, 0.0435]),\n",
       " tensor([0.0641, 0.0641, 0.0641, 0.0641, 0.0897, 0.1282, 0.2692, 0.2308, 0.0256]),\n",
       " tensor([0.0139, 0.0833, 0.1389, 0.2222, 0.3611, 0.0139, 0.0000, 0.0278, 0.1389]),\n",
       " tensor([0.1154, 0.1346, 0.0385, 0.0385, 0.3077, 0.0577, 0.0962, 0.1731, 0.0385]),\n",
       " tensor([0.0833, 0.1250, 0.1250, 0.0000, 0.2500, 0.0833, 0.0417, 0.0833, 0.2083]),\n",
       " tensor([0.0513, 0.3077, 0.0256, 0.0256, 0.0513, 0.2564, 0.0256, 0.1795, 0.0769]),\n",
       " tensor([0.0645, 0.0000, 0.0000, 0.0000, 0.0000, 0.2258, 0.2258, 0.4194, 0.0645]),\n",
       " tensor([0.1111, 0.0000, 0.0000, 0.0000, 0.0556, 0.1667, 0.3889, 0.2222, 0.0556]),\n",
       " tensor([0.0476, 0.1429, 0.1429, 0.0476, 0.3810, 0.0000, 0.1429, 0.0476, 0.0476]),\n",
       " tensor([0.0000, 0.2593, 0.0370, 0.1852, 0.2222, 0.0741, 0.0000, 0.0370, 0.1852]),\n",
       " tensor([0.1176, 0.1176, 0.0588, 0.1176, 0.4118, 0.0588, 0.0588, 0.0588, 0.0000]),\n",
       " tensor([0.0500, 0.0500, 0.0000, 0.0500, 0.0000, 0.5000, 0.3000, 0.0500, 0.0000]),\n",
       " tensor([0.1111, 0.0556, 0.0000, 0.0000, 0.0000, 0.1667, 0.1667, 0.4444, 0.0556]),\n",
       " tensor([0.0588, 0.1176, 0.0000, 0.0000, 0.1176, 0.2941, 0.1176, 0.2353, 0.0588]),\n",
       " tensor([0.1364, 0.1364, 0.1364, 0.0455, 0.1818, 0.2273, 0.0000, 0.1364, 0.0000]),\n",
       " tensor([0.0000, 0.2667, 0.0000, 0.0000, 0.0000, 0.2000, 0.0667, 0.4667, 0.0000]),\n",
       " tensor([0.0000, 0.2000, 0.0500, 0.0000, 0.1500, 0.1500, 0.1000, 0.2500, 0.1000]),\n",
       " tensor([0.0000, 0.1111, 0.0000, 0.0556, 0.0000, 0.2222, 0.3333, 0.2222, 0.0556]),\n",
       " tensor([0.0000, 0.2500, 0.0500, 0.1000, 0.2500, 0.0500, 0.0000, 0.2500, 0.0500]),\n",
       " tensor([0.0357, 0.1071, 0.0714, 0.1786, 0.2500, 0.0357, 0.0000, 0.1786, 0.1429]),\n",
       " tensor([0.0588, 0.1765, 0.0588, 0.0000, 0.0000, 0.1176, 0.2353, 0.2941, 0.0588]),\n",
       " tensor([0.0435, 0.3043, 0.0435, 0.0435, 0.2609, 0.1304, 0.0870, 0.0435, 0.0435]),\n",
       " tensor([0.0000, 0.1923, 0.0000, 0.3077, 0.2308, 0.0385, 0.0385, 0.0769, 0.1154]),\n",
       " tensor([0.0000, 0.1053, 0.0000, 0.1053, 0.0000, 0.3158, 0.1053, 0.2632, 0.1053]),\n",
       " tensor([0.0000, 0.2500, 0.0000, 0.0500, 0.1500, 0.1000, 0.0000, 0.2000, 0.2500]),\n",
       " tensor([0.0417, 0.1667, 0.0000, 0.1250, 0.1250, 0.1667, 0.1250, 0.1667, 0.0833]),\n",
       " tensor([0.1250, 0.2083, 0.0000, 0.0833, 0.2500, 0.0833, 0.0000, 0.1667, 0.0833]),\n",
       " tensor([0.0400, 0.1200, 0.0000, 0.0000, 0.0400, 0.4400, 0.0800, 0.2400, 0.0400]),\n",
       " tensor([0.0417, 0.2500, 0.1667, 0.1667, 0.2917, 0.0417, 0.0417, 0.0000, 0.0000]),\n",
       " tensor([0.1481, 0.1481, 0.0370, 0.0370, 0.0000, 0.2222, 0.1481, 0.1111, 0.1481]),\n",
       " tensor([0.0400, 0.1600, 0.0800, 0.1600, 0.1200, 0.0800, 0.0000, 0.1200, 0.2400]),\n",
       " tensor([0.0952, 0.1429, 0.0476, 0.0476, 0.0952, 0.0952, 0.1429, 0.2857, 0.0476]),\n",
       " tensor([0.0714, 0.1786, 0.0000, 0.0000, 0.1071, 0.1071, 0.2143, 0.2857, 0.0357]),\n",
       " tensor([0.0952, 0.0000, 0.0476, 0.0000, 0.0476, 0.2381, 0.0476, 0.3810, 0.1429]),\n",
       " tensor([0.1765, 0.0588, 0.0000, 0.1765, 0.0588, 0.0000, 0.2941, 0.1765, 0.0588]),\n",
       " tensor([0.0667, 0.1333, 0.0667, 0.1333, 0.3333, 0.0000, 0.0667, 0.2000, 0.0000]),\n",
       " tensor([0.0000, 0.0476, 0.1429, 0.0000, 0.2857, 0.0952, 0.2381, 0.1429, 0.0476]),\n",
       " tensor([0.0800, 0.2000, 0.0400, 0.0800, 0.1200, 0.0400, 0.0000, 0.3200, 0.1200]),\n",
       " tensor([0.0000, 0.1176, 0.0000, 0.0000, 0.0588, 0.0588, 0.0000, 0.5294, 0.2353]),\n",
       " tensor([0.0833, 0.1250, 0.0417, 0.0833, 0.2083, 0.0000, 0.0000, 0.2083, 0.2500]),\n",
       " tensor([0.1000, 0.0500, 0.0000, 0.0000, 0.0500, 0.2000, 0.3000, 0.3000, 0.0000]),\n",
       " tensor([0.0769, 0.1154, 0.0385, 0.0769, 0.0385, 0.1538, 0.1538, 0.2692, 0.0769]),\n",
       " tensor([0.0385, 0.1923, 0.0769, 0.1154, 0.1923, 0.0769, 0.0000, 0.1538, 0.1538]),\n",
       " tensor([0.0625, 0.0625, 0.0000, 0.0625, 0.0000, 0.1250, 0.3125, 0.3750, 0.0000]),\n",
       " tensor([0.1667, 0.0556, 0.0000, 0.0556, 0.0556, 0.1667, 0.4444, 0.0556, 0.0000]),\n",
       " tensor([0.0000, 0.0500, 0.0000, 0.1000, 0.0000, 0.2500, 0.2500, 0.2500, 0.1000]),\n",
       " tensor([0.0625, 0.0625, 0.0000, 0.0625, 0.0625, 0.0625, 0.4375, 0.2500, 0.0000]),\n",
       " tensor([0.0435, 0.2174, 0.0435, 0.0000, 0.0000, 0.3043, 0.2609, 0.0870, 0.0435]),\n",
       " tensor([0.1053, 0.1053, 0.1053, 0.0526, 0.3684, 0.0000, 0.0526, 0.1579, 0.0526]),\n",
       " tensor([0.0000, 0.1000, 0.0000, 0.1000, 0.0000, 0.1500, 0.3500, 0.2500, 0.0500]),\n",
       " tensor([0.0500, 0.1500, 0.0000, 0.0000, 0.0000, 0.3000, 0.2500, 0.2500, 0.0000]),\n",
       " tensor([0.0625, 0.0625, 0.0000, 0.2500, 0.0000, 0.1875, 0.3750, 0.0625, 0.0000]),\n",
       " tensor([0.0000, 0.2500, 0.0000, 0.1667, 0.2083, 0.0833, 0.0000, 0.2083, 0.0833]),\n",
       " tensor([0.1429, 0.0000, 0.0000, 0.0000, 0.1429, 0.1905, 0.3810, 0.1429, 0.0000]),\n",
       " tensor([0.1304, 0.1304, 0.0000, 0.0870, 0.0870, 0.1304, 0.2174, 0.2174, 0.0000]),\n",
       " tensor([0.0345, 0.2414, 0.0690, 0.0690, 0.3103, 0.0345, 0.0345, 0.1724, 0.0345]),\n",
       " tensor([0.0556, 0.2222, 0.0556, 0.0000, 0.3333, 0.0000, 0.1667, 0.1667, 0.0000]),\n",
       " tensor([0.0000, 0.1000, 0.0000, 0.0500, 0.1000, 0.2000, 0.1500, 0.3500, 0.0500]),\n",
       " tensor([0.0952, 0.0476, 0.0952, 0.0476, 0.2381, 0.0952, 0.2857, 0.0476, 0.0476]),\n",
       " tensor([0.1111, 0.1852, 0.0000, 0.1111, 0.2593, 0.0370, 0.1852, 0.0741, 0.0370]),\n",
       " tensor([0.0769, 0.2308, 0.0385, 0.0385, 0.2308, 0.0769, 0.0769, 0.0385, 0.1923]),\n",
       " tensor([0.0000, 0.2500, 0.0833, 0.1250, 0.2500, 0.0833, 0.0417, 0.1250, 0.0417]),\n",
       " tensor([0.0952, 0.0952, 0.0000, 0.0000, 0.1429, 0.1905, 0.2857, 0.1905, 0.0000]),\n",
       " tensor([0.0476, 0.0952, 0.0476, 0.0476, 0.0476, 0.3333, 0.1905, 0.1905, 0.0000]),\n",
       " tensor([0.1765, 0.1176, 0.1176, 0.0588, 0.2353, 0.0588, 0.1176, 0.0588, 0.0588]),\n",
       " tensor([0.0000, 0.0417, 0.1250, 0.1250, 0.2083, 0.0833, 0.2500, 0.1250, 0.0417]),\n",
       " tensor([0.0000, 0.2381, 0.0000, 0.0000, 0.0952, 0.2381, 0.0476, 0.1905, 0.1905]),\n",
       " tensor([0.0870, 0.0870, 0.0435, 0.0870, 0.1739, 0.0870, 0.2609, 0.0435, 0.1304]),\n",
       " tensor([0.0476, 0.2857, 0.0476, 0.0476, 0.1429, 0.0476, 0.0476, 0.1905, 0.1429]),\n",
       " tensor([0.1262, 0.0097, 0.2136, 0.2039, 0.1456, 0.0194, 0.1650, 0.0680, 0.0485]),\n",
       " tensor([0.0333, 0.0556, 0.2111, 0.1778, 0.2444, 0.0111, 0.1556, 0.0444, 0.0667]),\n",
       " tensor([0.0108, 0.1183, 0.1505, 0.1613, 0.1720, 0.0000, 0.0000, 0.1613, 0.2258]),\n",
       " tensor([0.1075, 0.1828, 0.0645, 0.1075, 0.0860, 0.1398, 0.0430, 0.1398, 0.1290]),\n",
       " tensor([0.0652, 0.0326, 0.2174, 0.2283, 0.1304, 0.0217, 0.1196, 0.0543, 0.1304]),\n",
       " tensor([0.0220, 0.0879, 0.1868, 0.2418, 0.2088, 0.0110, 0.0110, 0.0220, 0.2088]),\n",
       " tensor([0.0000, 0.0659, 0.2418, 0.2088, 0.2637, 0.0000, 0.0000, 0.0440, 0.1758]),\n",
       " tensor([0.0220, 0.1429, 0.0549, 0.2088, 0.2198, 0.0440, 0.0220, 0.0769, 0.2088]),\n",
       " tensor([0.0220, 0.0659, 0.0879, 0.1758, 0.2418, 0.0879, 0.0440, 0.1099, 0.1648]),\n",
       " tensor([0.0430, 0.1075, 0.0753, 0.2043, 0.1613, 0.0860, 0.0430, 0.0645, 0.2151]),\n",
       " tensor([0.0870, 0.0435, 0.0326, 0.0543, 0.0217, 0.1957, 0.2935, 0.2174, 0.0543]),\n",
       " tensor([0.0444, 0.0667, 0.1333, 0.2111, 0.3444, 0.0222, 0.0444, 0.0444, 0.0889]),\n",
       " tensor([0.0405, 0.1216, 0.1486, 0.1486, 0.2432, 0.0676, 0.1081, 0.0811, 0.0405]),\n",
       " tensor([0.0141, 0.1268, 0.1972, 0.1268, 0.3380, 0.0141, 0.0282, 0.0282, 0.1268]),\n",
       " tensor([0.0566, 0.1698, 0.0755, 0.0566, 0.0566, 0.1887, 0.1509, 0.1509, 0.0943]),\n",
       " tensor([0.0333, 0.1667, 0.0333, 0.0333, 0.1333, 0.0333, 0.0000, 0.4000, 0.1667]),\n",
       " tensor([0.1429, 0.0000, 0.0357, 0.0357, 0.0357, 0.3214, 0.2500, 0.1071, 0.0714]),\n",
       " tensor([0.0000, 0.1154, 0.0769, 0.2308, 0.3462, 0.0385, 0.0000, 0.0385, 0.1538]),\n",
       " tensor([0.0000, 0.0000, 0.0400, 0.2000, 0.2800, 0.0400, 0.1600, 0.2000, 0.0800]),\n",
       " tensor([0.0417, 0.0833, 0.1667, 0.2500, 0.1667, 0.0000, 0.0000, 0.0833, 0.2083]),\n",
       " tensor([0.0455, 0.0000, 0.1364, 0.0909, 0.2727, 0.0000, 0.0000, 0.2273, 0.2273]),\n",
       " tensor([0.0435, 0.0000, 0.3043, 0.1739, 0.3043, 0.0000, 0.0000, 0.0000, 0.1739]),\n",
       " tensor([0.0833, 0.0833, 0.0000, 0.0833, 0.0000, 0.0833, 0.4167, 0.2500, 0.0000]),\n",
       " tensor([0.0417, 0.0000, 0.0417, 0.3333, 0.0833, 0.0833, 0.1250, 0.0833, 0.2083]),\n",
       " tensor([0.0000, 0.1154, 0.0385, 0.1923, 0.0769, 0.1154, 0.0000, 0.1923, 0.2692]),\n",
       " tensor([0.0417, 0.0417, 0.2917, 0.2083, 0.0833, 0.0000, 0.1250, 0.0417, 0.1667]),\n",
       " tensor([0.0000, 0.0000, 0.2174, 0.2174, 0.3043, 0.0000, 0.0000, 0.0435, 0.2174]),\n",
       " tensor([0.0455, 0.0909, 0.1818, 0.2273, 0.1364, 0.1364, 0.0909, 0.0455, 0.0455]),\n",
       " tensor([0.0952, 0.0476, 0.0476, 0.0476, 0.0000, 0.1905, 0.4286, 0.1429, 0.0000]),\n",
       " tensor([0.0000, 0.1500, 0.1000, 0.3500, 0.2000, 0.0000, 0.0500, 0.1000, 0.0500]),\n",
       " tensor([0.0385, 0.0769, 0.0769, 0.2692, 0.2692, 0.0769, 0.0769, 0.0000, 0.1154]),\n",
       " tensor([0.0000, 0.1739, 0.0000, 0.1739, 0.1739, 0.0435, 0.0000, 0.3043, 0.1304]),\n",
       " tensor([0.0833, 0.0417, 0.1667, 0.2917, 0.0417, 0.0417, 0.1667, 0.0000, 0.1667]),\n",
       " tensor([0.0500, 0.0000, 0.1500, 0.2000, 0.3500, 0.0000, 0.0000, 0.0500, 0.2000]),\n",
       " tensor([0.0000, 0.0500, 0.0000, 0.1000, 0.0000, 0.3000, 0.2500, 0.2000, 0.1000]),\n",
       " tensor([0.0000, 0.0556, 0.0000, 0.0556, 0.1111, 0.1111, 0.2778, 0.3333, 0.0556]),\n",
       " tensor([0.0500, 0.2500, 0.0000, 0.0500, 0.2000, 0.1500, 0.0500, 0.1000, 0.1500]),\n",
       " tensor([0.0435, 0.0870, 0.1304, 0.0870, 0.2609, 0.0870, 0.1739, 0.1304, 0.0000]),\n",
       " tensor([0.0556, 0.1111, 0.1667, 0.1667, 0.0556, 0.0556, 0.0000, 0.2778, 0.1111]),\n",
       " tensor([0.1053, 0.0000, 0.0000, 0.1053, 0.0526, 0.1579, 0.2105, 0.3684, 0.0000]),\n",
       " tensor([0.0000, 0.0417, 0.2500, 0.3333, 0.2083, 0.0000, 0.0000, 0.0000, 0.1667]),\n",
       " tensor([0.0769, 0.1154, 0.2692, 0.1538, 0.1923, 0.0385, 0.0000, 0.0385, 0.1154]),\n",
       " tensor([0.0000, 0.0769, 0.1923, 0.1923, 0.2308, 0.0000, 0.0385, 0.1154, 0.1538]),\n",
       " tensor([0.0769, 0.1154, 0.0769, 0.2308, 0.4231, 0.0000, 0.0385, 0.0000, 0.0385]),\n",
       " tensor([0.0606, 0.0606, 0.1515, 0.1212, 0.2121, 0.0606, 0.1818, 0.0606, 0.0909]),\n",
       " tensor([0.2143, 0.1071, 0.1071, 0.1786, 0.2500, 0.0357, 0.0714, 0.0000, 0.0357]),\n",
       " tensor([0.1000, 0.1333, 0.0000, 0.0333, 0.0333, 0.1667, 0.2667, 0.2000, 0.0667]),\n",
       " tensor([0.0000, 0.1364, 0.2273, 0.1364, 0.0909, 0.0455, 0.0455, 0.0455, 0.2727]),\n",
       " tensor([0.0400, 0.1200, 0.1200, 0.0400, 0.0800, 0.0800, 0.0800, 0.2400, 0.2000]),\n",
       " tensor([0.0952, 0.0476, 0.0000, 0.0476, 0.0000, 0.3810, 0.4286, 0.0000, 0.0000]),\n",
       " tensor([0.1739, 0.0000, 0.0435, 0.2609, 0.1739, 0.0435, 0.2174, 0.0435, 0.0435]),\n",
       " tensor([0.0417, 0.0417, 0.1250, 0.1667, 0.2500, 0.0000, 0.0000, 0.1250, 0.2500]),\n",
       " tensor([0.0000, 0.0476, 0.2381, 0.3333, 0.0476, 0.0000, 0.0000, 0.0952, 0.2381]),\n",
       " tensor([0.0800, 0.1600, 0.0000, 0.0800, 0.0000, 0.1600, 0.0000, 0.2400, 0.2800]),\n",
       " tensor([0.0385, 0.0385, 0.2308, 0.1154, 0.1538, 0.0385, 0.3846, 0.0000, 0.0000]),\n",
       " tensor([0.0345, 0.1034, 0.1379, 0.1379, 0.3103, 0.0000, 0.1724, 0.0345, 0.0690]),\n",
       " tensor([0.0435, 0.0435, 0.0000, 0.0000, 0.0000, 0.3478, 0.3043, 0.2609, 0.0000]),\n",
       " tensor([0.0400, 0.0800, 0.2400, 0.1600, 0.2400, 0.0000, 0.1200, 0.0000, 0.1200]),\n",
       " tensor([0.0000, 0.0000, 0.2174, 0.2609, 0.3043, 0.0000, 0.1304, 0.0870, 0.0000]),\n",
       " tensor([0.0741, 0.0370, 0.1852, 0.2593, 0.1852, 0.0000, 0.0370, 0.0370, 0.1852]),\n",
       " tensor([0.0833, 0.0417, 0.3750, 0.2083, 0.2083, 0.0000, 0.0417, 0.0000, 0.0417]),\n",
       " tensor([0.1111, 0.0000, 0.1111, 0.1852, 0.0741, 0.2222, 0.2222, 0.0370, 0.0370]),\n",
       " tensor([0.0526, 0.0000, 0.0526, 0.2105, 0.1579, 0.0526, 0.4737, 0.0000, 0.0000]),\n",
       " tensor([0.0952, 0.0000, 0.0476, 0.1429, 0.0476, 0.0952, 0.3333, 0.1429, 0.0952]),\n",
       " tensor([0.0435, 0.0000, 0.1739, 0.2174, 0.3913, 0.0000, 0.0000, 0.0870, 0.0870]),\n",
       " tensor([0.1250, 0.0000, 0.0000, 0.2917, 0.0417, 0.2500, 0.1667, 0.1250, 0.0000]),\n",
       " tensor([0.1481, 0.0370, 0.2593, 0.0741, 0.0000, 0.1111, 0.3704, 0.0000, 0.0000]),\n",
       " tensor([0.1000, 0.0000, 0.1500, 0.1500, 0.2000, 0.1000, 0.2000, 0.0500, 0.0500]),\n",
       " tensor([0.2105, 0.0526, 0.0526, 0.1053, 0.1053, 0.1053, 0.0526, 0.2105, 0.1053]),\n",
       " tensor([0.0455, 0.0000, 0.0000, 0.0909, 0.0000, 0.2727, 0.2273, 0.3182, 0.0455]),\n",
       " tensor([0.2083, 0.0833, 0.1667, 0.1667, 0.0417, 0.0000, 0.2500, 0.0833, 0.0000]),\n",
       " tensor([0.0833, 0.0417, 0.2500, 0.1250, 0.1667, 0.0000, 0.1250, 0.0417, 0.1667]),\n",
       " tensor([0.1364, 0.0000, 0.0909, 0.0909, 0.0000, 0.1364, 0.4091, 0.0909, 0.0455]),\n",
       " tensor([0.0385, 0.0000, 0.2692, 0.1923, 0.3077, 0.0000, 0.0385, 0.0000, 0.1538]),\n",
       " tensor([0.0690, 0.2069, 0.1034, 0.1379, 0.2069, 0.0000, 0.0690, 0.1379, 0.0690]),\n",
       " tensor([0.1034, 0.0345, 0.0000, 0.1034, 0.0000, 0.2414, 0.2414, 0.1724, 0.1034]),\n",
       " tensor([0.1304, 0.0870, 0.1304, 0.2609, 0.1739, 0.0000, 0.0870, 0.0435, 0.0870]),\n",
       " tensor([0.0476, 0.0476, 0.0476, 0.0952, 0.0952, 0.1905, 0.0000, 0.1905, 0.2857]),\n",
       " tensor([0.1250, 0.0000, 0.0000, 0.1667, 0.1250, 0.0833, 0.2917, 0.1250, 0.0833]),\n",
       " tensor([0.1212, 0.0303, 0.2121, 0.2121, 0.2424, 0.0303, 0.0606, 0.0000, 0.0909])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongEmotionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Song Emotion Dataset. Uses librosa to process mp3 files.\n",
    "    Takes first 20 seconds, and samples every 10 to get processed audio tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mp3, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mp3: list of paths to mp3 files\n",
    "            labels: list of labels\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.mp3 = mp3\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data, rate = librosa.load(self.mp3[index], sr=16000, duration=20)\n",
    "        print(self.mp3)\n",
    "        assert rate == 16000\n",
    "        sample_tensor = torch.tensor(data, device=device).float()\n",
    "        downsampled_tensor = sample_tensor[::10]\n",
    "        \n",
    "        return downsampled_tensor, F.softmax(self.labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 128, kernel_size=(80,), stride=(4,))\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgPool): AvgPool1d(kernel_size=(30,), stride=(30,), padding=(0,))\n",
      "  (fc1): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 128, 80, 4)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(128, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(256, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.avgPool = nn.AvgPool1d(30) #input should be 512x30 so this outputs a 512x1\n",
    "        self.fc1 = nn.Linear(512, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim = 2)\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 320\n",
      "Test set size: 80\n"
     ]
    }
   ],
   "source": [
    "train_set = SongEmotionDataset(train_song, train_emotion)\n",
    "test_set = SongEmotionDataset(test_song, test_emotion)\n",
    "print(\"Train set size: \" + str(len(train_set)))\n",
    "print(\"Test set size: \" + str(len(test_set)))\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {} #needed for using datasets on gpu\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 8, shuffle = True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 8, shuffle = True, **kwargs)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data.unsqueeze_(1)\n",
    "        data = data.requires_grad_() #set requires_grad to True for training\n",
    "        output = model(data)\n",
    "        output = output.view(-1, len(emotions))\n",
    "#         print(output.shape, target.shape)\n",
    "#         print(output, target)\n",
    "        loss = F.kl_div(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0: #print training stats\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data.unsqueeze_(1)\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        pred = output.max(2)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.max(1)[1]).cpu().sum().item()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/czf/memories/venv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/czf/memories/venv/lib/python3.6/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/czf/memories/SongEmotionModel/data/113.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0;32m-> 1184\u001b[0;31m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening '/home/czf/memories/SongEmotionModel/data/113.mp3': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-362d7d1dddfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First round of training complete. Setting learn rate to 0.001.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-7ae7f86ad13d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-10e88ba7699b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PySoundFile failed. Trying audioread instead.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/venv/lib/python3.6/site-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/czf/memories/SongEmotionModel/data/113.mp3'"
     ]
    }
   ],
   "source": [
    "log_interval = 5\n",
    "for epoch in range(1, 41):\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "    scheduler.step()\n",
    "    train(model, epoch)\n",
    "    test(model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "\n",
    "below is the mfccs notes / random code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio, sample_rate = librosa.load(\"SongEmotionDataset/1.mp3\", res_type='kaiser_fast')\n",
    "# # [print(x) for x in audio]\n",
    "\n",
    "# #convert audio into 2d array\n",
    "# mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "# # mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "# print(mfccs.shape, audio.shape)\n",
    "# mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_tensor = torch.tensor(audio)\n",
    "# audio_tensor\n",
    "# audio_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sound_file in data_path.iterdir():\n",
    "#     if \".mp3\" in str(sound_file):\n",
    "#         print(sound_file)\n",
    "#         audio, sample_rate = librosa.load(str(sound_file), res_type='kaiser_fast')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
