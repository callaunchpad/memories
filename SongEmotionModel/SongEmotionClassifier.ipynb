{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import decorators\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        track id   genre amazement     calmness  power  joyful_activation  \\\n",
      "0              1     NaN         7           30      1                  4   \n",
      "1              2     NaN         5           35      2                  1   \n",
      "2              3     NaN         8            3     13                 19   \n",
      "3              4     NaN         5           32      1                  0   \n",
      "4              5     NaN         2           14      2                  3   \n",
      "..           ...     ...       ...          ...    ...                ...   \n",
      "397          398     NaN         3            3      2                  7   \n",
      "398          399     NaN         4            8      1                  2   \n",
      "399          400     NaN         3            1      0                  3   \n",
      "400  Grand Total     NaN      1119         2561   1531               2145   \n",
      "401          NaN     NaN       awe  contentment  anger         excitement   \n",
      "\n",
      "     sadness  \n",
      "0         15  \n",
      "1          5  \n",
      "2          7  \n",
      "3          6  \n",
      "4         14  \n",
      "..       ...  \n",
      "397        2  \n",
      "398        3  \n",
      "399        5  \n",
      "400     1544  \n",
      "401  sadness  \n",
      "\n",
      "[402 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# read in the data file\n",
    "# Give the location of the file \n",
    "\n",
    "df = pd.read_excel(r'data.xlsx', sheet_name='reduced totals')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlyzfeng/launchpad/memories/venv/lib/python3.8/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 2586) (1323648,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.7718567e+02, -3.5018188e+02, -3.2727213e+02, ...,\n",
       "        -2.3304880e+02, -1.7282356e+02, -1.7300600e+02],\n",
       "       [ 5.4867729e+01,  1.2169147e+02,  1.3046588e+02, ...,\n",
       "         1.5205682e+02,  1.3713069e+02,  1.2564399e+02],\n",
       "       [ 1.7319386e+01, -6.4998174e+00, -1.1335234e+01, ...,\n",
       "        -2.4199781e+01, -1.8155302e+01, -1.7164921e+01],\n",
       "       ...,\n",
       "       [-2.5546131e+00,  1.4165753e-01,  3.2487426e+00, ...,\n",
       "        -3.0164802e+00, -3.8806877e+00, -3.8585839e+00],\n",
       "       [-8.8357747e-01, -2.9985919e+00, -3.2912343e+00, ...,\n",
       "        -1.2004358e+01, -4.5422392e+00, -3.8063698e+00],\n",
       "       [-4.1244268e-02, -1.5693712e-01, -3.0035594e+00, ...,\n",
       "        -9.5676631e-01,  1.4220479e+00, -7.0910168e-01]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio, sample_rate = librosa.load(\"SongEmotionDataset/1.mp3\", res_type='kaiser_fast')\n",
    "# [print(x) for x in audio]\n",
    "\n",
    "#convert audio into 2d array\n",
    "mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "# mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "print(mfccs.shape, audio.shape)\n",
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.7719e+02, -3.5018e+02, -3.2727e+02,  ..., -2.3305e+02,\n",
       "         -1.7282e+02, -1.7301e+02],\n",
       "        [ 5.4868e+01,  1.2169e+02,  1.3047e+02,  ...,  1.5206e+02,\n",
       "          1.3713e+02,  1.2564e+02],\n",
       "        [ 1.7319e+01, -6.4998e+00, -1.1335e+01,  ..., -2.4200e+01,\n",
       "         -1.8155e+01, -1.7165e+01],\n",
       "        ...,\n",
       "        [-2.5546e+00,  1.4166e-01,  3.2487e+00,  ..., -3.0165e+00,\n",
       "         -3.8807e+00, -3.8586e+00],\n",
       "        [-8.8358e-01, -2.9986e+00, -3.2912e+00,  ..., -1.2004e+01,\n",
       "         -4.5422e+00, -3.8064e+00],\n",
       "        [-4.1244e-02, -1.5694e-01, -3.0036e+00,  ..., -9.5677e-01,\n",
       "          1.4220e+00, -7.0910e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_tensor = torch.tensor(mfccs)\n",
    "audio_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 128, 80, 4)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(128, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(256, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.avgPool = nn.AvgPool1d(30) #input should be 512x30 so this outputs a 512x1\n",
    "        self.fc1 = nn.Linear(512, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim = 2)\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
