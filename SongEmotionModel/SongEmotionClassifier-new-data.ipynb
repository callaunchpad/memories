{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import decorators\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data file\n",
    "# Give the location of the file \n",
    "\n",
    "df = pd.read_excel(r'data/data.xlsx', sheet_name='totals')\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING IN DATASETS\n",
    "\n",
    "dataset = Path.cwd().joinpath(\"SongEmotionDataset\")\n",
    "datasheet = Path.cwd().joinpath(\"data\") # for csua\n",
    "\n",
    "#emotion labels\n",
    "label_loc = datasheet.joinpath(\"data.xlsx\")\n",
    "wb = xlrd.open_workbook(label_loc) \n",
    "sheet = wb.sheet_by_index(2) #1 for 9 columns, 2 for 5 columns\n",
    "\n",
    "#emotion arr\n",
    "emotions = [\"amazement\", \"calmness\", \"power\", \"joyful activation\", \"sadness\"]\n",
    "# emotions = [\"amazement\", \"solemnity\", \"tenderness\", \"nostalgia\", \"calmness\", \"power\", \"joyful activation\", \"tension\", \"sadness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 11.4343, 157.9054,  55.5535, 120.1633,  54.9434], device='cuda:0')\n",
      "tensor([3.1112, 9.2133, 7.9749, 8.9079, 7.7927], device='cuda:0')\n",
      "[1, 9, 9, 11, 7]\n"
     ]
    }
   ],
   "source": [
    "train_percentage = 0.8\n",
    "allowed_exceedance = 0\n",
    "\n",
    "train_song = []\n",
    "test_song = []\n",
    "train_emotion = []\n",
    "test_emotion = []\n",
    "\n",
    "row_indexes = np.arange(1,401)\n",
    "np.random.shuffle(row_indexes)\n",
    "\n",
    "# train_indexes = [row_indexes[i] for i in range(len(row_indexes)) if i < len(row_indexes)*train_percentage]\n",
    "# test_indexes = [row_indexes[i] for i in range(len(row_indexes)) if i >= len(row_indexes)*train_percentage]\n",
    "\n",
    "def get_data(indexes):\n",
    "    song = []\n",
    "    emotion = []\n",
    "    \n",
    "    totals = torch.zeros(len(emotions), device=device).float()\n",
    "    for x in indexes:    \n",
    "        row = torch.tensor([sheet.cell_value(x, 2 + j) for j in range(5)], device=device).float()\n",
    "        totals += F.softmax(row)\n",
    "\n",
    "    min_total = torch.min(totals)\n",
    "    print(totals)\n",
    "    \n",
    "    totals = torch.zeros(len(emotions), device=device).float()\n",
    "    for x in indexes:\n",
    "        row = torch.tensor([sheet.cell_value(x, 2 + j) for j in range(5)], device=device).float()\n",
    "        \n",
    "        if torch.max(totals + row) < min_total*(1 + allowed_exceedance):\n",
    "            song.append(dataset.joinpath(\"{}.mp3\".format(x)))\n",
    "            emotion.append(row)\n",
    "            totals += F.softmax(row)\n",
    "            \n",
    "    print(totals)\n",
    "    return song, emotion\n",
    "    \n",
    "song, emotion = get_data(row_indexes)\n",
    "# test_song, test_emotion = get_data(test_indexes)\n",
    "\n",
    "train_song = [song[i] for i in range(len(song)) if i < len(song)*train_percentage]\n",
    "test_song = [song[i] for i in range(len(song)) if i >= len(song)*train_percentage]\n",
    "\n",
    "train_emotion = [emotion[i] for i in range(len(emotion)) if i < len(emotion)*train_percentage]\n",
    "test_emotion = [emotion[i] for i in range(len(emotion)) if i >= len(emotion)*train_percentage]\n",
    "\n",
    "num_maxes = [0 for _ in emotions]\n",
    "\n",
    "for row in emotion:\n",
    "    i = torch.argmax(row)\n",
    "    num_maxes[i] += 1\n",
    "    \n",
    "print(num_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_song = []\n",
    "# test_song = []\n",
    "# train_emotion = []\n",
    "# test_emotion = []\n",
    "\n",
    "# for i in range(1, 401):\n",
    "#     count_total = sheet.cell_value(i, 11)\n",
    "#     if i % 5 == 0:\n",
    "#         test_song.append(dataset.joinpath(\"{}.mp3\".format(i)))\n",
    "#         emotion_arr = []\n",
    "#         for j in range(9):\n",
    "#             emotion_arr.append(sheet.cell_value(i, 2 + j))\n",
    "#         test_emotion.append(torch.tensor(emotion_arr, device=device).float())\n",
    "#     else:\n",
    "#         train_song.append(dataset.joinpath(\"{}.mp3\".format(i)))\n",
    "#         emotion_arr = []\n",
    "#         for j in range(9):\n",
    "#             emotion_arr.append(sheet.cell_value(i, 2 + j))\n",
    "#         train_emotion.append(torch.tensor(emotion_arr, device=device))\n",
    "\n",
    "# print(len(train_song), len(test_song))\n",
    "# print(len(train_emotion), len(test_emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([5., 1., 0., 6., 0.], device='cuda:0'),\n",
       " tensor([ 1.,  0., 11.,  2.,  4.], device='cuda:0'),\n",
       " tensor([4., 8., 1., 0., 5.], device='cuda:0'),\n",
       " tensor([3., 4., 0., 1., 4.], device='cuda:0'),\n",
       " tensor([0., 4., 3., 3., 2.], device='cuda:0'),\n",
       " tensor([2., 5., 2., 7., 1.], device='cuda:0'),\n",
       " tensor([3., 0., 3., 9., 1.], device='cuda:0'),\n",
       " tensor([1., 7., 1., 1., 0.], device='cuda:0'),\n",
       " tensor([2., 8., 3., 4., 2.], device='cuda:0'),\n",
       " tensor([3., 1., 0., 5., 1.], device='cuda:0'),\n",
       " tensor([2., 6., 2., 1., 5.], device='cuda:0'),\n",
       " tensor([0., 5., 2., 6., 1.], device='cuda:0'),\n",
       " tensor([2., 0., 3., 3., 1.], device='cuda:0'),\n",
       " tensor([2., 5., 3., 1., 2.], device='cuda:0'),\n",
       " tensor([4., 0., 5., 6., 2.], device='cuda:0'),\n",
       " tensor([1., 1., 7., 5., 1.], device='cuda:0'),\n",
       " tensor([3., 3., 3., 4., 2.], device='cuda:0'),\n",
       " tensor([3., 2., 3., 5., 0.], device='cuda:0'),\n",
       " tensor([0., 3., 2., 0., 5.], device='cuda:0'),\n",
       " tensor([2., 5., 0., 1., 1.], device='cuda:0'),\n",
       " tensor([1., 2., 0., 3., 4.], device='cuda:0'),\n",
       " tensor([2., 0., 4., 0., 7.], device='cuda:0'),\n",
       " tensor([1., 1., 1., 0., 2.], device='cuda:0'),\n",
       " tensor([3., 4., 5., 3., 3.], device='cuda:0'),\n",
       " tensor([0., 2., 1., 4., 2.], device='cuda:0'),\n",
       " tensor([3., 3., 1., 2., 2.], device='cuda:0'),\n",
       " tensor([2., 2., 2., 3., 1.], device='cuda:0'),\n",
       " tensor([1., 3., 2., 0., 6.], device='cuda:0'),\n",
       " tensor([4., 0., 7., 1., 1.], device='cuda:0'),\n",
       " tensor([0., 1., 1., 0., 4.], device='cuda:0')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongEmotionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Song Emotion Dataset. Uses librosa to process mp3 files.\n",
    "    Takes first 20 seconds, and samples every 10 to get processed audio tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mp3, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mp3: list of paths to mp3 files\n",
    "            labels: list of labels\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.mp3 = mp3\n",
    "        self.cache = {}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index not in self.cache.keys():\n",
    "#             print(\"index of \" + str(index) + \" was cached!\")\n",
    "            data, rate = librosa.load(self.mp3[index], sr=16000, duration=10)\n",
    "            assert rate == 16000\n",
    "            sample_tensor = torch.tensor(data, device=device).float()\n",
    "            downsampled_tensor = sample_tensor[::10]\n",
    "\n",
    "            self.cache[index] = (downsampled_tensor, F.softmax(self.labels[index]))\n",
    "#         else:\n",
    "#             print(\"index was cached! index of \" + str(index))\n",
    "#         print(self.cache[index])\n",
    "        return self.cache[index]\n",
    "\n",
    "        \n",
    "#         data, rate = librosa.load(self.mp3[index], sr=16000, duration=20)\n",
    "#         assert rate == 16000\n",
    "#         sample_tensor = torch.tensor(data, device=device).float()\n",
    "#         downsampled_tensor = sample_tensor[::10]\n",
    "        \n",
    "#         print(downsampled_tensor, F.softmax(self.labels[index]))\n",
    "        \n",
    "#         return downsampled_tensor, F.softmax(self.labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 128, kernel_size=(80,), stride=(4,))\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgPool): AvgPool1d(kernel_size=(14,), stride=(14,), padding=(0,))\n",
      "  (fc1): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 128, 80, 4)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(128, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(256, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.avgPool = nn.AvgPool1d(14) #input should be 512x30 so this outputs a 512x1\n",
    "        self.fc1 = nn.Linear(512, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim = 2)\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 30\n",
      "Test set size: 7\n"
     ]
    }
   ],
   "source": [
    "train_set = SongEmotionDataset(train_song, train_emotion)\n",
    "test_set = SongEmotionDataset(test_song, test_emotion)\n",
    "print(\"Train set size: \" + str(len(train_set)))\n",
    "print(\"Test set size: \" + str(len(test_set)))\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {} #needed for using datasets on gpu\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 8, shuffle = True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 8, shuffle = True, **kwargs)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data.unsqueeze_(1)\n",
    "        data = data.requires_grad_() #set requires_grad to True for training\n",
    "        output = model(data)\n",
    "        output = output.view(-1, len(emotions))\n",
    "#         print(output.shape, target.shape)\n",
    "#         print(output, target)\n",
    "        loss = F.kl_div(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         scheduler.step()\n",
    "        if batch_idx % log_interval == 0: #print training stats\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data.unsqueeze_(1)\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        pred = output.max(2)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.max(1)[1]).cpu().sum().item()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1\n",
      "Train Epoch: 1 [0/30 (0%)]\tLoss: 0.357652\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 2\n",
      "Train Epoch: 2 [0/30 (0%)]\tLoss: 0.400630\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 3\n",
      "Train Epoch: 3 [0/30 (0%)]\tLoss: 0.294863\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 4\n",
      "Train Epoch: 4 [0/30 (0%)]\tLoss: 0.181267\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 5\n",
      "Train Epoch: 5 [0/30 (0%)]\tLoss: 0.331421\n",
      "\n",
      "Test set: Accuracy: 4/7 (57%)\n",
      "\n",
      "training epoch 6\n",
      "Train Epoch: 6 [0/30 (0%)]\tLoss: 0.141754\n",
      "\n",
      "Test set: Accuracy: 4/7 (57%)\n",
      "\n",
      "training epoch 7\n",
      "Train Epoch: 7 [0/30 (0%)]\tLoss: 0.155763\n",
      "\n",
      "Test set: Accuracy: 2/7 (29%)\n",
      "\n",
      "training epoch 8\n",
      "Train Epoch: 8 [0/30 (0%)]\tLoss: 0.273586\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 9\n",
      "Train Epoch: 9 [0/30 (0%)]\tLoss: 0.160892\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 10\n",
      "Train Epoch: 10 [0/30 (0%)]\tLoss: 0.092102\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 11\n",
      "Train Epoch: 11 [0/30 (0%)]\tLoss: 0.091153\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 12\n",
      "Train Epoch: 12 [0/30 (0%)]\tLoss: 0.083824\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 13\n",
      "Train Epoch: 13 [0/30 (0%)]\tLoss: 0.114733\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 14\n",
      "Train Epoch: 14 [0/30 (0%)]\tLoss: 0.128645\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 15\n",
      "Train Epoch: 15 [0/30 (0%)]\tLoss: 0.073246\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 16\n",
      "Train Epoch: 16 [0/30 (0%)]\tLoss: 0.128639\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 17\n",
      "Train Epoch: 17 [0/30 (0%)]\tLoss: 0.073885\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 18\n",
      "Train Epoch: 18 [0/30 (0%)]\tLoss: 0.166959\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 19\n",
      "Train Epoch: 19 [0/30 (0%)]\tLoss: 0.096457\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 20\n",
      "Train Epoch: 20 [0/30 (0%)]\tLoss: 0.123688\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 21\n",
      "Train Epoch: 21 [0/30 (0%)]\tLoss: 0.112364\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 22\n",
      "Train Epoch: 22 [0/30 (0%)]\tLoss: 0.087435\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 23\n",
      "Train Epoch: 23 [0/30 (0%)]\tLoss: 0.082622\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 24\n",
      "Train Epoch: 24 [0/30 (0%)]\tLoss: 0.064625\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 25\n",
      "Train Epoch: 25 [0/30 (0%)]\tLoss: 0.073946\n",
      "\n",
      "Test set: Accuracy: 0/7 (0%)\n",
      "\n",
      "training epoch 26\n",
      "Train Epoch: 26 [0/30 (0%)]\tLoss: 0.062735\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 27\n",
      "Train Epoch: 27 [0/30 (0%)]\tLoss: 0.088624\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 28\n",
      "Train Epoch: 28 [0/30 (0%)]\tLoss: 0.115372\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 29\n",
      "Train Epoch: 29 [0/30 (0%)]\tLoss: 0.049312\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 30\n",
      "Train Epoch: 30 [0/30 (0%)]\tLoss: 0.157553\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 31\n",
      "First round of training complete. Setting learn rate to 0.001.\n",
      "Train Epoch: 31 [0/30 (0%)]\tLoss: 0.082334\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 32\n",
      "Train Epoch: 32 [0/30 (0%)]\tLoss: 0.061374\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 33\n",
      "Train Epoch: 33 [0/30 (0%)]\tLoss: 0.042918\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 34\n",
      "Train Epoch: 34 [0/30 (0%)]\tLoss: 0.091511\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 35\n",
      "Train Epoch: 35 [0/30 (0%)]\tLoss: 0.070775\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 36\n",
      "Train Epoch: 36 [0/30 (0%)]\tLoss: 0.104733\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 37\n",
      "Train Epoch: 37 [0/30 (0%)]\tLoss: 0.080746\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 38\n",
      "Train Epoch: 38 [0/30 (0%)]\tLoss: 0.087406\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 39\n",
      "Train Epoch: 39 [0/30 (0%)]\tLoss: 0.082548\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n",
      "training epoch 40\n",
      "Train Epoch: 40 [0/30 (0%)]\tLoss: 0.057182\n",
      "\n",
      "Test set: Accuracy: 1/7 (14%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#w caching & data processing\n",
    "import warnings\n",
    "\n",
    "log_interval = 5\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for epoch in range(1, 41):\n",
    "    print(\"training epoch \" + str(epoch))\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "#     scheduler.step()\n",
    "    train(model, epoch)\n",
    "    scheduler.step()\n",
    "    test(model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1\n",
      "Train Epoch: 1 [0/320 (0%)]\tLoss: 0.191720\n",
      "Train Epoch: 1 [40/320 (12%)]\tLoss: 0.329261\n",
      "Train Epoch: 1 [80/320 (25%)]\tLoss: 0.284903\n",
      "Train Epoch: 1 [120/320 (38%)]\tLoss: 0.338861\n",
      "Train Epoch: 1 [160/320 (50%)]\tLoss: 0.210636\n",
      "Train Epoch: 1 [200/320 (62%)]\tLoss: 0.167495\n",
      "Train Epoch: 1 [240/320 (75%)]\tLoss: 0.162565\n",
      "Train Epoch: 1 [280/320 (88%)]\tLoss: 0.321939\n",
      "\n",
      "Test set: Accuracy: 19/80 (24%)\n",
      "\n",
      "training epoch 2\n",
      "Train Epoch: 2 [0/320 (0%)]\tLoss: 0.210194\n",
      "Train Epoch: 2 [40/320 (12%)]\tLoss: 0.201684\n",
      "Train Epoch: 2 [80/320 (25%)]\tLoss: 0.117230\n",
      "Train Epoch: 2 [120/320 (38%)]\tLoss: 0.207198\n",
      "Train Epoch: 2 [160/320 (50%)]\tLoss: 0.188115\n",
      "Train Epoch: 2 [200/320 (62%)]\tLoss: 0.190015\n",
      "Train Epoch: 2 [240/320 (75%)]\tLoss: 0.140593\n",
      "Train Epoch: 2 [280/320 (88%)]\tLoss: 0.213586\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 3\n",
      "Train Epoch: 3 [0/320 (0%)]\tLoss: 0.127676\n",
      "Train Epoch: 3 [40/320 (12%)]\tLoss: 0.175529\n",
      "Train Epoch: 3 [80/320 (25%)]\tLoss: 0.160134\n",
      "Train Epoch: 3 [120/320 (38%)]\tLoss: 0.157589\n",
      "Train Epoch: 3 [160/320 (50%)]\tLoss: 0.168349\n",
      "Train Epoch: 3 [200/320 (62%)]\tLoss: 0.149061\n",
      "Train Epoch: 3 [240/320 (75%)]\tLoss: 0.154252\n",
      "Train Epoch: 3 [280/320 (88%)]\tLoss: 0.180634\n",
      "\n",
      "Test set: Accuracy: 23/80 (29%)\n",
      "\n",
      "training epoch 4\n",
      "Train Epoch: 4 [0/320 (0%)]\tLoss: 0.153863\n",
      "Train Epoch: 4 [40/320 (12%)]\tLoss: 0.170401\n",
      "Train Epoch: 4 [80/320 (25%)]\tLoss: 0.116388\n",
      "Train Epoch: 4 [120/320 (38%)]\tLoss: 0.124060\n",
      "Train Epoch: 4 [160/320 (50%)]\tLoss: 0.143214\n",
      "Train Epoch: 4 [200/320 (62%)]\tLoss: 0.179630\n",
      "Train Epoch: 4 [240/320 (75%)]\tLoss: 0.188496\n",
      "Train Epoch: 4 [280/320 (88%)]\tLoss: 0.182668\n",
      "\n",
      "Test set: Accuracy: 23/80 (29%)\n",
      "\n",
      "training epoch 5\n",
      "Train Epoch: 5 [0/320 (0%)]\tLoss: 0.146198\n",
      "Train Epoch: 5 [40/320 (12%)]\tLoss: 0.151484\n",
      "Train Epoch: 5 [80/320 (25%)]\tLoss: 0.144369\n",
      "Train Epoch: 5 [120/320 (38%)]\tLoss: 0.135824\n",
      "Train Epoch: 5 [160/320 (50%)]\tLoss: 0.147213\n",
      "Train Epoch: 5 [200/320 (62%)]\tLoss: 0.169771\n",
      "Train Epoch: 5 [240/320 (75%)]\tLoss: 0.166857\n",
      "Train Epoch: 5 [280/320 (88%)]\tLoss: 0.110782\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 6\n",
      "Train Epoch: 6 [0/320 (0%)]\tLoss: 0.148035\n",
      "Train Epoch: 6 [40/320 (12%)]\tLoss: 0.132011\n",
      "Train Epoch: 6 [80/320 (25%)]\tLoss: 0.172618\n",
      "Train Epoch: 6 [120/320 (38%)]\tLoss: 0.164004\n",
      "Train Epoch: 6 [160/320 (50%)]\tLoss: 0.099142\n",
      "Train Epoch: 6 [200/320 (62%)]\tLoss: 0.131375\n",
      "Train Epoch: 6 [240/320 (75%)]\tLoss: 0.168143\n",
      "Train Epoch: 6 [280/320 (88%)]\tLoss: 0.174055\n",
      "\n",
      "Test set: Accuracy: 22/80 (28%)\n",
      "\n",
      "training epoch 7\n",
      "Train Epoch: 7 [0/320 (0%)]\tLoss: 0.105413\n",
      "Train Epoch: 7 [40/320 (12%)]\tLoss: 0.137166\n",
      "Train Epoch: 7 [80/320 (25%)]\tLoss: 0.142146\n",
      "Train Epoch: 7 [120/320 (38%)]\tLoss: 0.193170\n",
      "Train Epoch: 7 [160/320 (50%)]\tLoss: 0.148268\n",
      "Train Epoch: 7 [200/320 (62%)]\tLoss: 0.143546\n",
      "Train Epoch: 7 [240/320 (75%)]\tLoss: 0.133050\n",
      "Train Epoch: 7 [280/320 (88%)]\tLoss: 0.134236\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 8\n",
      "Train Epoch: 8 [0/320 (0%)]\tLoss: 0.128067\n",
      "Train Epoch: 8 [40/320 (12%)]\tLoss: 0.138545\n",
      "Train Epoch: 8 [80/320 (25%)]\tLoss: 0.158826\n",
      "Train Epoch: 8 [120/320 (38%)]\tLoss: 0.131687\n",
      "Train Epoch: 8 [160/320 (50%)]\tLoss: 0.187674\n",
      "Train Epoch: 8 [200/320 (62%)]\tLoss: 0.121796\n",
      "Train Epoch: 8 [240/320 (75%)]\tLoss: 0.147160\n",
      "Train Epoch: 8 [280/320 (88%)]\tLoss: 0.203417\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 9\n",
      "Train Epoch: 9 [0/320 (0%)]\tLoss: 0.164306\n",
      "Train Epoch: 9 [40/320 (12%)]\tLoss: 0.165597\n",
      "Train Epoch: 9 [80/320 (25%)]\tLoss: 0.122330\n",
      "Train Epoch: 9 [120/320 (38%)]\tLoss: 0.111132\n",
      "Train Epoch: 9 [160/320 (50%)]\tLoss: 0.127811\n",
      "Train Epoch: 9 [200/320 (62%)]\tLoss: 0.131876\n",
      "Train Epoch: 9 [240/320 (75%)]\tLoss: 0.117554\n",
      "Train Epoch: 9 [280/320 (88%)]\tLoss: 0.151157\n",
      "\n",
      "Test set: Accuracy: 23/80 (29%)\n",
      "\n",
      "training epoch 10\n",
      "Train Epoch: 10 [0/320 (0%)]\tLoss: 0.147492\n",
      "Train Epoch: 10 [40/320 (12%)]\tLoss: 0.136711\n",
      "Train Epoch: 10 [80/320 (25%)]\tLoss: 0.158314\n",
      "Train Epoch: 10 [120/320 (38%)]\tLoss: 0.119198\n",
      "Train Epoch: 10 [160/320 (50%)]\tLoss: 0.118704\n",
      "Train Epoch: 10 [200/320 (62%)]\tLoss: 0.153009\n",
      "Train Epoch: 10 [240/320 (75%)]\tLoss: 0.189993\n",
      "Train Epoch: 10 [280/320 (88%)]\tLoss: 0.132757\n",
      "\n",
      "Test set: Accuracy: 24/80 (30%)\n",
      "\n",
      "training epoch 11\n",
      "Train Epoch: 11 [0/320 (0%)]\tLoss: 0.148846\n",
      "Train Epoch: 11 [40/320 (12%)]\tLoss: 0.139574\n",
      "Train Epoch: 11 [80/320 (25%)]\tLoss: 0.160432\n",
      "Train Epoch: 11 [120/320 (38%)]\tLoss: 0.174024\n",
      "Train Epoch: 11 [160/320 (50%)]\tLoss: 0.161915\n",
      "Train Epoch: 11 [200/320 (62%)]\tLoss: 0.110037\n",
      "Train Epoch: 11 [240/320 (75%)]\tLoss: 0.162453\n",
      "Train Epoch: 11 [280/320 (88%)]\tLoss: 0.139737\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 12\n",
      "Train Epoch: 12 [0/320 (0%)]\tLoss: 0.150581\n",
      "Train Epoch: 12 [40/320 (12%)]\tLoss: 0.166083\n",
      "Train Epoch: 12 [80/320 (25%)]\tLoss: 0.152030\n",
      "Train Epoch: 12 [120/320 (38%)]\tLoss: 0.161329\n",
      "Train Epoch: 12 [160/320 (50%)]\tLoss: 0.164096\n",
      "Train Epoch: 12 [200/320 (62%)]\tLoss: 0.144470\n",
      "Train Epoch: 12 [240/320 (75%)]\tLoss: 0.114608\n",
      "Train Epoch: 12 [280/320 (88%)]\tLoss: 0.144294\n",
      "\n",
      "Test set: Accuracy: 24/80 (30%)\n",
      "\n",
      "training epoch 13\n",
      "Train Epoch: 13 [0/320 (0%)]\tLoss: 0.150582\n",
      "Train Epoch: 13 [40/320 (12%)]\tLoss: 0.119003\n",
      "Train Epoch: 13 [80/320 (25%)]\tLoss: 0.137122\n",
      "Train Epoch: 13 [120/320 (38%)]\tLoss: 0.130961\n",
      "Train Epoch: 13 [160/320 (50%)]\tLoss: 0.140995\n",
      "Train Epoch: 13 [200/320 (62%)]\tLoss: 0.139647\n",
      "Train Epoch: 13 [240/320 (75%)]\tLoss: 0.129678\n",
      "Train Epoch: 13 [280/320 (88%)]\tLoss: 0.138817\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 14\n",
      "Train Epoch: 14 [0/320 (0%)]\tLoss: 0.168014\n",
      "Train Epoch: 14 [40/320 (12%)]\tLoss: 0.119383\n",
      "Train Epoch: 14 [80/320 (25%)]\tLoss: 0.211341\n",
      "Train Epoch: 14 [120/320 (38%)]\tLoss: 0.121242\n",
      "Train Epoch: 14 [160/320 (50%)]\tLoss: 0.120812\n",
      "Train Epoch: 14 [200/320 (62%)]\tLoss: 0.144962\n",
      "Train Epoch: 14 [240/320 (75%)]\tLoss: 0.123729\n",
      "Train Epoch: 14 [280/320 (88%)]\tLoss: 0.118727\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 15\n",
      "Train Epoch: 15 [0/320 (0%)]\tLoss: 0.115412\n",
      "Train Epoch: 15 [40/320 (12%)]\tLoss: 0.188811\n",
      "Train Epoch: 15 [80/320 (25%)]\tLoss: 0.128344\n",
      "Train Epoch: 15 [120/320 (38%)]\tLoss: 0.149197\n",
      "Train Epoch: 15 [160/320 (50%)]\tLoss: 0.103601\n",
      "Train Epoch: 15 [200/320 (62%)]\tLoss: 0.143465\n",
      "Train Epoch: 15 [240/320 (75%)]\tLoss: 0.162857\n",
      "Train Epoch: 15 [280/320 (88%)]\tLoss: 0.169206\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 16\n",
      "Train Epoch: 16 [0/320 (0%)]\tLoss: 0.144088\n",
      "Train Epoch: 16 [40/320 (12%)]\tLoss: 0.130324\n",
      "Train Epoch: 16 [80/320 (25%)]\tLoss: 0.147940\n",
      "Train Epoch: 16 [120/320 (38%)]\tLoss: 0.138095\n",
      "Train Epoch: 16 [160/320 (50%)]\tLoss: 0.109504\n",
      "Train Epoch: 16 [200/320 (62%)]\tLoss: 0.160420\n",
      "Train Epoch: 16 [240/320 (75%)]\tLoss: 0.167246\n",
      "Train Epoch: 16 [280/320 (88%)]\tLoss: 0.142288\n",
      "\n",
      "Test set: Accuracy: 24/80 (30%)\n",
      "\n",
      "training epoch 17\n",
      "Train Epoch: 17 [0/320 (0%)]\tLoss: 0.140414\n",
      "Train Epoch: 17 [40/320 (12%)]\tLoss: 0.148044\n",
      "Train Epoch: 17 [80/320 (25%)]\tLoss: 0.117693\n",
      "Train Epoch: 17 [120/320 (38%)]\tLoss: 0.143165\n",
      "Train Epoch: 17 [160/320 (50%)]\tLoss: 0.140589\n",
      "Train Epoch: 17 [200/320 (62%)]\tLoss: 0.172596\n",
      "Train Epoch: 17 [240/320 (75%)]\tLoss: 0.129349\n",
      "Train Epoch: 17 [280/320 (88%)]\tLoss: 0.117940\n",
      "\n",
      "Test set: Accuracy: 31/80 (39%)\n",
      "\n",
      "training epoch 18\n",
      "Train Epoch: 18 [0/320 (0%)]\tLoss: 0.119135\n",
      "Train Epoch: 18 [40/320 (12%)]\tLoss: 0.190739\n",
      "Train Epoch: 18 [80/320 (25%)]\tLoss: 0.161680\n",
      "Train Epoch: 18 [120/320 (38%)]\tLoss: 0.132813\n",
      "Train Epoch: 18 [160/320 (50%)]\tLoss: 0.171426\n",
      "Train Epoch: 18 [200/320 (62%)]\tLoss: 0.135142\n",
      "Train Epoch: 18 [240/320 (75%)]\tLoss: 0.155324\n",
      "Train Epoch: 18 [280/320 (88%)]\tLoss: 0.137221\n",
      "\n",
      "Test set: Accuracy: 21/80 (26%)\n",
      "\n",
      "training epoch 19\n",
      "Train Epoch: 19 [0/320 (0%)]\tLoss: 0.126812\n",
      "Train Epoch: 19 [40/320 (12%)]\tLoss: 0.154804\n",
      "Train Epoch: 19 [80/320 (25%)]\tLoss: 0.110585\n",
      "Train Epoch: 19 [120/320 (38%)]\tLoss: 0.136034\n",
      "Train Epoch: 19 [160/320 (50%)]\tLoss: 0.124886\n",
      "Train Epoch: 19 [200/320 (62%)]\tLoss: 0.148867\n",
      "Train Epoch: 19 [240/320 (75%)]\tLoss: 0.123274\n",
      "Train Epoch: 19 [280/320 (88%)]\tLoss: 0.120195\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n",
      "training epoch 20\n",
      "Train Epoch: 20 [0/320 (0%)]\tLoss: 0.119467\n",
      "Train Epoch: 20 [40/320 (12%)]\tLoss: 0.129316\n",
      "Train Epoch: 20 [80/320 (25%)]\tLoss: 0.101322\n",
      "Train Epoch: 20 [120/320 (38%)]\tLoss: 0.098406\n",
      "Train Epoch: 20 [160/320 (50%)]\tLoss: 0.128697\n",
      "Train Epoch: 20 [200/320 (62%)]\tLoss: 0.160592\n",
      "Train Epoch: 20 [240/320 (75%)]\tLoss: 0.123497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [280/320 (88%)]\tLoss: 0.164417\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n",
      "training epoch 21\n",
      "Train Epoch: 21 [0/320 (0%)]\tLoss: 0.088417\n",
      "Train Epoch: 21 [40/320 (12%)]\tLoss: 0.127397\n",
      "Train Epoch: 21 [80/320 (25%)]\tLoss: 0.162288\n",
      "Train Epoch: 21 [120/320 (38%)]\tLoss: 0.132321\n",
      "Train Epoch: 21 [160/320 (50%)]\tLoss: 0.123884\n",
      "Train Epoch: 21 [200/320 (62%)]\tLoss: 0.132901\n",
      "Train Epoch: 21 [240/320 (75%)]\tLoss: 0.092551\n",
      "Train Epoch: 21 [280/320 (88%)]\tLoss: 0.152662\n",
      "\n",
      "Test set: Accuracy: 29/80 (36%)\n",
      "\n",
      "training epoch 22\n",
      "Train Epoch: 22 [0/320 (0%)]\tLoss: 0.099070\n",
      "Train Epoch: 22 [40/320 (12%)]\tLoss: 0.107604\n",
      "Train Epoch: 22 [80/320 (25%)]\tLoss: 0.164107\n",
      "Train Epoch: 22 [120/320 (38%)]\tLoss: 0.155712\n",
      "Train Epoch: 22 [160/320 (50%)]\tLoss: 0.088193\n",
      "Train Epoch: 22 [200/320 (62%)]\tLoss: 0.099478\n",
      "Train Epoch: 22 [240/320 (75%)]\tLoss: 0.130642\n",
      "Train Epoch: 22 [280/320 (88%)]\tLoss: 0.101703\n",
      "\n",
      "Test set: Accuracy: 29/80 (36%)\n",
      "\n",
      "training epoch 23\n",
      "Train Epoch: 23 [0/320 (0%)]\tLoss: 0.141142\n",
      "Train Epoch: 23 [40/320 (12%)]\tLoss: 0.086931\n",
      "Train Epoch: 23 [80/320 (25%)]\tLoss: 0.119440\n",
      "Train Epoch: 23 [120/320 (38%)]\tLoss: 0.134644\n",
      "Train Epoch: 23 [160/320 (50%)]\tLoss: 0.090799\n",
      "Train Epoch: 23 [200/320 (62%)]\tLoss: 0.103606\n",
      "Train Epoch: 23 [240/320 (75%)]\tLoss: 0.155308\n",
      "Train Epoch: 23 [280/320 (88%)]\tLoss: 0.107537\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n",
      "training epoch 24\n",
      "Train Epoch: 24 [0/320 (0%)]\tLoss: 0.121201\n",
      "Train Epoch: 24 [40/320 (12%)]\tLoss: 0.141290\n",
      "Train Epoch: 24 [80/320 (25%)]\tLoss: 0.117531\n",
      "Train Epoch: 24 [120/320 (38%)]\tLoss: 0.123993\n",
      "Train Epoch: 24 [160/320 (50%)]\tLoss: 0.147009\n",
      "Train Epoch: 24 [200/320 (62%)]\tLoss: 0.087602\n",
      "Train Epoch: 24 [240/320 (75%)]\tLoss: 0.129175\n",
      "Train Epoch: 24 [280/320 (88%)]\tLoss: 0.149384\n",
      "\n",
      "Test set: Accuracy: 29/80 (36%)\n",
      "\n",
      "training epoch 25\n",
      "Train Epoch: 25 [0/320 (0%)]\tLoss: 0.127346\n",
      "Train Epoch: 25 [40/320 (12%)]\tLoss: 0.087091\n",
      "Train Epoch: 25 [80/320 (25%)]\tLoss: 0.113754\n",
      "Train Epoch: 25 [120/320 (38%)]\tLoss: 0.115145\n",
      "Train Epoch: 25 [160/320 (50%)]\tLoss: 0.066550\n",
      "Train Epoch: 25 [200/320 (62%)]\tLoss: 0.125560\n",
      "Train Epoch: 25 [240/320 (75%)]\tLoss: 0.117185\n",
      "Train Epoch: 25 [280/320 (88%)]\tLoss: 0.107832\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 26\n",
      "Train Epoch: 26 [0/320 (0%)]\tLoss: 0.090539\n",
      "Train Epoch: 26 [40/320 (12%)]\tLoss: 0.071152\n",
      "Train Epoch: 26 [80/320 (25%)]\tLoss: 0.082525\n",
      "Train Epoch: 26 [120/320 (38%)]\tLoss: 0.138505\n",
      "Train Epoch: 26 [160/320 (50%)]\tLoss: 0.139483\n",
      "Train Epoch: 26 [200/320 (62%)]\tLoss: 0.173734\n",
      "Train Epoch: 26 [240/320 (75%)]\tLoss: 0.096552\n",
      "Train Epoch: 26 [280/320 (88%)]\tLoss: 0.112132\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 27\n",
      "Train Epoch: 27 [0/320 (0%)]\tLoss: 0.114917\n",
      "Train Epoch: 27 [40/320 (12%)]\tLoss: 0.126686\n",
      "Train Epoch: 27 [80/320 (25%)]\tLoss: 0.118474\n",
      "Train Epoch: 27 [120/320 (38%)]\tLoss: 0.148894\n",
      "Train Epoch: 27 [160/320 (50%)]\tLoss: 0.089145\n",
      "Train Epoch: 27 [200/320 (62%)]\tLoss: 0.130509\n",
      "Train Epoch: 27 [240/320 (75%)]\tLoss: 0.126584\n",
      "Train Epoch: 27 [280/320 (88%)]\tLoss: 0.069998\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n",
      "training epoch 28\n",
      "Train Epoch: 28 [0/320 (0%)]\tLoss: 0.109808\n",
      "Train Epoch: 28 [40/320 (12%)]\tLoss: 0.088457\n",
      "Train Epoch: 28 [80/320 (25%)]\tLoss: 0.116812\n",
      "Train Epoch: 28 [120/320 (38%)]\tLoss: 0.101893\n",
      "Train Epoch: 28 [160/320 (50%)]\tLoss: 0.101277\n",
      "Train Epoch: 28 [200/320 (62%)]\tLoss: 0.109269\n",
      "Train Epoch: 28 [240/320 (75%)]\tLoss: 0.061327\n",
      "Train Epoch: 28 [280/320 (88%)]\tLoss: 0.102560\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 29\n",
      "Train Epoch: 29 [0/320 (0%)]\tLoss: 0.075848\n",
      "Train Epoch: 29 [40/320 (12%)]\tLoss: 0.091220\n",
      "Train Epoch: 29 [80/320 (25%)]\tLoss: 0.086960\n",
      "Train Epoch: 29 [120/320 (38%)]\tLoss: 0.090697\n",
      "Train Epoch: 29 [160/320 (50%)]\tLoss: 0.088046\n",
      "Train Epoch: 29 [200/320 (62%)]\tLoss: 0.123191\n",
      "Train Epoch: 29 [240/320 (75%)]\tLoss: 0.098705\n",
      "Train Epoch: 29 [280/320 (88%)]\tLoss: 0.097021\n",
      "\n",
      "Test set: Accuracy: 31/80 (39%)\n",
      "\n",
      "training epoch 30\n",
      "Train Epoch: 30 [0/320 (0%)]\tLoss: 0.113539\n",
      "Train Epoch: 30 [40/320 (12%)]\tLoss: 0.132801\n",
      "Train Epoch: 30 [80/320 (25%)]\tLoss: 0.100028\n",
      "Train Epoch: 30 [120/320 (38%)]\tLoss: 0.075523\n",
      "Train Epoch: 30 [160/320 (50%)]\tLoss: 0.115936\n",
      "Train Epoch: 30 [200/320 (62%)]\tLoss: 0.087016\n",
      "Train Epoch: 30 [240/320 (75%)]\tLoss: 0.114637\n",
      "Train Epoch: 30 [280/320 (88%)]\tLoss: 0.123242\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 31\n",
      "First round of training complete. Setting learn rate to 0.001.\n",
      "Train Epoch: 31 [0/320 (0%)]\tLoss: 0.162124\n",
      "Train Epoch: 31 [40/320 (12%)]\tLoss: 0.130128\n",
      "Train Epoch: 31 [80/320 (25%)]\tLoss: 0.098175\n",
      "Train Epoch: 31 [120/320 (38%)]\tLoss: 0.094875\n",
      "Train Epoch: 31 [160/320 (50%)]\tLoss: 0.104179\n",
      "Train Epoch: 31 [200/320 (62%)]\tLoss: 0.123220\n",
      "Train Epoch: 31 [240/320 (75%)]\tLoss: 0.077964\n",
      "Train Epoch: 31 [280/320 (88%)]\tLoss: 0.096107\n",
      "\n",
      "Test set: Accuracy: 26/80 (32%)\n",
      "\n",
      "training epoch 32\n",
      "Train Epoch: 32 [0/320 (0%)]\tLoss: 0.100305\n",
      "Train Epoch: 32 [40/320 (12%)]\tLoss: 0.076191\n",
      "Train Epoch: 32 [80/320 (25%)]\tLoss: 0.116749\n",
      "Train Epoch: 32 [120/320 (38%)]\tLoss: 0.117503\n",
      "Train Epoch: 32 [160/320 (50%)]\tLoss: 0.124027\n",
      "Train Epoch: 32 [200/320 (62%)]\tLoss: 0.114248\n",
      "Train Epoch: 32 [240/320 (75%)]\tLoss: 0.140314\n",
      "Train Epoch: 32 [280/320 (88%)]\tLoss: 0.092640\n",
      "\n",
      "Test set: Accuracy: 26/80 (32%)\n",
      "\n",
      "training epoch 33\n",
      "Train Epoch: 33 [0/320 (0%)]\tLoss: 0.063985\n",
      "Train Epoch: 33 [40/320 (12%)]\tLoss: 0.093553\n",
      "Train Epoch: 33 [80/320 (25%)]\tLoss: 0.162095\n",
      "Train Epoch: 33 [120/320 (38%)]\tLoss: 0.073497\n",
      "Train Epoch: 33 [160/320 (50%)]\tLoss: 0.080685\n",
      "Train Epoch: 33 [200/320 (62%)]\tLoss: 0.156388\n",
      "Train Epoch: 33 [240/320 (75%)]\tLoss: 0.103222\n",
      "Train Epoch: 33 [280/320 (88%)]\tLoss: 0.114256\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 34\n",
      "Train Epoch: 34 [0/320 (0%)]\tLoss: 0.180098\n",
      "Train Epoch: 34 [40/320 (12%)]\tLoss: 0.118888\n",
      "Train Epoch: 34 [80/320 (25%)]\tLoss: 0.105681\n",
      "Train Epoch: 34 [120/320 (38%)]\tLoss: 0.134795\n",
      "Train Epoch: 34 [160/320 (50%)]\tLoss: 0.085446\n",
      "Train Epoch: 34 [200/320 (62%)]\tLoss: 0.120967\n",
      "Train Epoch: 34 [240/320 (75%)]\tLoss: 0.086351\n",
      "Train Epoch: 34 [280/320 (88%)]\tLoss: 0.060270\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 35\n",
      "Train Epoch: 35 [0/320 (0%)]\tLoss: 0.119876\n",
      "Train Epoch: 35 [40/320 (12%)]\tLoss: 0.107494\n",
      "Train Epoch: 35 [80/320 (25%)]\tLoss: 0.127480\n",
      "Train Epoch: 35 [120/320 (38%)]\tLoss: 0.133158\n",
      "Train Epoch: 35 [160/320 (50%)]\tLoss: 0.083494\n",
      "Train Epoch: 35 [200/320 (62%)]\tLoss: 0.068871\n",
      "Train Epoch: 35 [240/320 (75%)]\tLoss: 0.093150\n",
      "Train Epoch: 35 [280/320 (88%)]\tLoss: 0.093793\n",
      "\n",
      "Test set: Accuracy: 23/80 (29%)\n",
      "\n",
      "training epoch 36\n",
      "Train Epoch: 36 [0/320 (0%)]\tLoss: 0.099313\n",
      "Train Epoch: 36 [40/320 (12%)]\tLoss: 0.132149\n",
      "Train Epoch: 36 [80/320 (25%)]\tLoss: 0.078016\n",
      "Train Epoch: 36 [120/320 (38%)]\tLoss: 0.123311\n",
      "Train Epoch: 36 [160/320 (50%)]\tLoss: 0.082142\n",
      "Train Epoch: 36 [200/320 (62%)]\tLoss: 0.075490\n",
      "Train Epoch: 36 [240/320 (75%)]\tLoss: 0.115610\n",
      "Train Epoch: 36 [280/320 (88%)]\tLoss: 0.138755\n",
      "\n",
      "Test set: Accuracy: 29/80 (36%)\n",
      "\n",
      "training epoch 37\n",
      "Train Epoch: 37 [0/320 (0%)]\tLoss: 0.088953\n",
      "Train Epoch: 37 [40/320 (12%)]\tLoss: 0.155244\n",
      "Train Epoch: 37 [80/320 (25%)]\tLoss: 0.096527\n",
      "Train Epoch: 37 [120/320 (38%)]\tLoss: 0.067456\n",
      "Train Epoch: 37 [160/320 (50%)]\tLoss: 0.087665\n",
      "Train Epoch: 37 [200/320 (62%)]\tLoss: 0.095266\n",
      "Train Epoch: 37 [240/320 (75%)]\tLoss: 0.093823\n",
      "Train Epoch: 37 [280/320 (88%)]\tLoss: 0.086571\n",
      "\n",
      "Test set: Accuracy: 25/80 (31%)\n",
      "\n",
      "training epoch 38\n",
      "Train Epoch: 38 [0/320 (0%)]\tLoss: 0.088359\n",
      "Train Epoch: 38 [40/320 (12%)]\tLoss: 0.080159\n",
      "Train Epoch: 38 [80/320 (25%)]\tLoss: 0.103364\n",
      "Train Epoch: 38 [120/320 (38%)]\tLoss: 0.081327\n",
      "Train Epoch: 38 [160/320 (50%)]\tLoss: 0.074994\n",
      "Train Epoch: 38 [200/320 (62%)]\tLoss: 0.106419\n",
      "Train Epoch: 38 [240/320 (75%)]\tLoss: 0.100416\n",
      "Train Epoch: 38 [280/320 (88%)]\tLoss: 0.122042\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 39\n",
      "Train Epoch: 39 [0/320 (0%)]\tLoss: 0.066890\n",
      "Train Epoch: 39 [40/320 (12%)]\tLoss: 0.076454\n",
      "Train Epoch: 39 [80/320 (25%)]\tLoss: 0.103561\n",
      "Train Epoch: 39 [120/320 (38%)]\tLoss: 0.091741\n",
      "Train Epoch: 39 [160/320 (50%)]\tLoss: 0.208292\n",
      "Train Epoch: 39 [200/320 (62%)]\tLoss: 0.063992\n",
      "Train Epoch: 39 [240/320 (75%)]\tLoss: 0.101293\n",
      "Train Epoch: 39 [280/320 (88%)]\tLoss: 0.085218\n",
      "\n",
      "Test set: Accuracy: 25/80 (31%)\n",
      "\n",
      "training epoch 40\n",
      "Train Epoch: 40 [0/320 (0%)]\tLoss: 0.108266\n",
      "Train Epoch: 40 [40/320 (12%)]\tLoss: 0.065104\n",
      "Train Epoch: 40 [80/320 (25%)]\tLoss: 0.110390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [120/320 (38%)]\tLoss: 0.133885\n",
      "Train Epoch: 40 [160/320 (50%)]\tLoss: 0.145604\n",
      "Train Epoch: 40 [200/320 (62%)]\tLoss: 0.060129\n",
      "Train Epoch: 40 [240/320 (75%)]\tLoss: 0.087228\n",
      "Train Epoch: 40 [280/320 (88%)]\tLoss: 0.111683\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#W/ CACHING\n",
    "import warnings\n",
    "\n",
    "log_interval = 5\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for epoch in range(1, 41):\n",
    "    print(\"training epoch \" + str(epoch))\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "#     scheduler.step()\n",
    "    train(model, epoch)\n",
    "    scheduler.step()\n",
    "    test(model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1\n",
      "Train Epoch: 1 [0/320 (0%)]\tLoss: 0.238086\n",
      "Train Epoch: 1 [40/320 (12%)]\tLoss: 0.543195\n",
      "Train Epoch: 1 [80/320 (25%)]\tLoss: 0.277862\n",
      "Train Epoch: 1 [120/320 (38%)]\tLoss: 0.275000\n",
      "Train Epoch: 1 [160/320 (50%)]\tLoss: 0.128894\n",
      "Train Epoch: 1 [200/320 (62%)]\tLoss: 0.191396\n",
      "Train Epoch: 1 [240/320 (75%)]\tLoss: 0.220283\n",
      "Train Epoch: 1 [280/320 (88%)]\tLoss: 0.195243\n",
      "\n",
      "Test set: Accuracy: 21/80 (26%)\n",
      "\n",
      "training epoch 2\n",
      "Train Epoch: 2 [0/320 (0%)]\tLoss: 0.170415\n",
      "Train Epoch: 2 [40/320 (12%)]\tLoss: 0.197089\n",
      "Train Epoch: 2 [80/320 (25%)]\tLoss: 0.203403\n",
      "Train Epoch: 2 [120/320 (38%)]\tLoss: 0.202500\n",
      "Train Epoch: 2 [160/320 (50%)]\tLoss: 0.189248\n",
      "Train Epoch: 2 [200/320 (62%)]\tLoss: 0.190571\n",
      "Train Epoch: 2 [240/320 (75%)]\tLoss: 0.205890\n",
      "Train Epoch: 2 [280/320 (88%)]\tLoss: 0.166318\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 3\n",
      "Train Epoch: 3 [0/320 (0%)]\tLoss: 0.150036\n",
      "Train Epoch: 3 [40/320 (12%)]\tLoss: 0.133074\n",
      "Train Epoch: 3 [80/320 (25%)]\tLoss: 0.141485\n",
      "Train Epoch: 3 [120/320 (38%)]\tLoss: 0.186608\n",
      "Train Epoch: 3 [160/320 (50%)]\tLoss: 0.174406\n",
      "Train Epoch: 3 [200/320 (62%)]\tLoss: 0.170449\n",
      "Train Epoch: 3 [240/320 (75%)]\tLoss: 0.207569\n",
      "Train Epoch: 3 [280/320 (88%)]\tLoss: 0.147904\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 4\n",
      "Train Epoch: 4 [0/320 (0%)]\tLoss: 0.154219\n",
      "Train Epoch: 4 [40/320 (12%)]\tLoss: 0.158806\n",
      "Train Epoch: 4 [80/320 (25%)]\tLoss: 0.156023\n",
      "Train Epoch: 4 [120/320 (38%)]\tLoss: 0.142820\n",
      "Train Epoch: 4 [160/320 (50%)]\tLoss: 0.131893\n",
      "Train Epoch: 4 [200/320 (62%)]\tLoss: 0.139679\n",
      "Train Epoch: 4 [240/320 (75%)]\tLoss: 0.166096\n",
      "Train Epoch: 4 [280/320 (88%)]\tLoss: 0.149600\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 5\n",
      "Train Epoch: 5 [0/320 (0%)]\tLoss: 0.164960\n",
      "Train Epoch: 5 [40/320 (12%)]\tLoss: 0.145892\n",
      "Train Epoch: 5 [80/320 (25%)]\tLoss: 0.130076\n",
      "Train Epoch: 5 [120/320 (38%)]\tLoss: 0.225643\n",
      "Train Epoch: 5 [160/320 (50%)]\tLoss: 0.138466\n",
      "Train Epoch: 5 [200/320 (62%)]\tLoss: 0.122993\n",
      "Train Epoch: 5 [240/320 (75%)]\tLoss: 0.172815\n",
      "Train Epoch: 5 [280/320 (88%)]\tLoss: 0.146358\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 6\n",
      "Train Epoch: 6 [0/320 (0%)]\tLoss: 0.182183\n",
      "Train Epoch: 6 [40/320 (12%)]\tLoss: 0.169643\n",
      "Train Epoch: 6 [80/320 (25%)]\tLoss: 0.174136\n",
      "Train Epoch: 6 [120/320 (38%)]\tLoss: 0.139435\n",
      "Train Epoch: 6 [160/320 (50%)]\tLoss: 0.136533\n",
      "Train Epoch: 6 [200/320 (62%)]\tLoss: 0.108325\n",
      "Train Epoch: 6 [240/320 (75%)]\tLoss: 0.151947\n",
      "Train Epoch: 6 [280/320 (88%)]\tLoss: 0.147493\n",
      "\n",
      "Test set: Accuracy: 25/80 (31%)\n",
      "\n",
      "training epoch 7\n",
      "Train Epoch: 7 [0/320 (0%)]\tLoss: 0.157394\n",
      "Train Epoch: 7 [40/320 (12%)]\tLoss: 0.127231\n",
      "Train Epoch: 7 [80/320 (25%)]\tLoss: 0.154646\n",
      "Train Epoch: 7 [120/320 (38%)]\tLoss: 0.149551\n",
      "Train Epoch: 7 [160/320 (50%)]\tLoss: 0.151091\n",
      "Train Epoch: 7 [200/320 (62%)]\tLoss: 0.177884\n",
      "Train Epoch: 7 [240/320 (75%)]\tLoss: 0.143260\n",
      "Train Epoch: 7 [280/320 (88%)]\tLoss: 0.149940\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n",
      "training epoch 8\n",
      "Train Epoch: 8 [0/320 (0%)]\tLoss: 0.151844\n",
      "Train Epoch: 8 [40/320 (12%)]\tLoss: 0.159664\n",
      "Train Epoch: 8 [80/320 (25%)]\tLoss: 0.128205\n",
      "Train Epoch: 8 [120/320 (38%)]\tLoss: 0.195776\n",
      "Train Epoch: 8 [160/320 (50%)]\tLoss: 0.131025\n",
      "Train Epoch: 8 [200/320 (62%)]\tLoss: 0.152956\n",
      "Train Epoch: 8 [240/320 (75%)]\tLoss: 0.179723\n",
      "Train Epoch: 8 [280/320 (88%)]\tLoss: 0.139764\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 9\n",
      "Train Epoch: 9 [0/320 (0%)]\tLoss: 0.140411\n",
      "Train Epoch: 9 [40/320 (12%)]\tLoss: 0.136212\n",
      "Train Epoch: 9 [80/320 (25%)]\tLoss: 0.179193\n",
      "Train Epoch: 9 [120/320 (38%)]\tLoss: 0.119092\n",
      "Train Epoch: 9 [160/320 (50%)]\tLoss: 0.193237\n",
      "Train Epoch: 9 [200/320 (62%)]\tLoss: 0.138030\n",
      "Train Epoch: 9 [240/320 (75%)]\tLoss: 0.223285\n",
      "Train Epoch: 9 [280/320 (88%)]\tLoss: 0.147284\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 10\n",
      "Train Epoch: 10 [0/320 (0%)]\tLoss: 0.119645\n",
      "Train Epoch: 10 [40/320 (12%)]\tLoss: 0.114722\n",
      "Train Epoch: 10 [80/320 (25%)]\tLoss: 0.154636\n",
      "Train Epoch: 10 [120/320 (38%)]\tLoss: 0.165610\n",
      "Train Epoch: 10 [160/320 (50%)]\tLoss: 0.163765\n",
      "Train Epoch: 10 [200/320 (62%)]\tLoss: 0.164531\n",
      "Train Epoch: 10 [240/320 (75%)]\tLoss: 0.115436\n",
      "Train Epoch: 10 [280/320 (88%)]\tLoss: 0.159676\n",
      "\n",
      "Test set: Accuracy: 26/80 (32%)\n",
      "\n",
      "training epoch 11\n",
      "Train Epoch: 11 [0/320 (0%)]\tLoss: 0.129056\n",
      "Train Epoch: 11 [40/320 (12%)]\tLoss: 0.105648\n",
      "Train Epoch: 11 [80/320 (25%)]\tLoss: 0.139317\n",
      "Train Epoch: 11 [120/320 (38%)]\tLoss: 0.120449\n",
      "Train Epoch: 11 [160/320 (50%)]\tLoss: 0.156765\n",
      "Train Epoch: 11 [200/320 (62%)]\tLoss: 0.121326\n",
      "Train Epoch: 11 [240/320 (75%)]\tLoss: 0.148824\n",
      "Train Epoch: 11 [280/320 (88%)]\tLoss: 0.133836\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 12\n",
      "Train Epoch: 12 [0/320 (0%)]\tLoss: 0.167767\n",
      "Train Epoch: 12 [40/320 (12%)]\tLoss: 0.099086\n",
      "Train Epoch: 12 [80/320 (25%)]\tLoss: 0.167303\n",
      "Train Epoch: 12 [120/320 (38%)]\tLoss: 0.144167\n",
      "Train Epoch: 12 [160/320 (50%)]\tLoss: 0.109036\n",
      "Train Epoch: 12 [200/320 (62%)]\tLoss: 0.121921\n",
      "Train Epoch: 12 [240/320 (75%)]\tLoss: 0.155197\n",
      "Train Epoch: 12 [280/320 (88%)]\tLoss: 0.094654\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 13\n",
      "Train Epoch: 13 [0/320 (0%)]\tLoss: 0.112444\n",
      "Train Epoch: 13 [40/320 (12%)]\tLoss: 0.143936\n",
      "Train Epoch: 13 [80/320 (25%)]\tLoss: 0.155205\n",
      "Train Epoch: 13 [120/320 (38%)]\tLoss: 0.123804\n",
      "Train Epoch: 13 [160/320 (50%)]\tLoss: 0.142318\n",
      "Train Epoch: 13 [200/320 (62%)]\tLoss: 0.117651\n",
      "Train Epoch: 13 [240/320 (75%)]\tLoss: 0.159394\n",
      "Train Epoch: 13 [280/320 (88%)]\tLoss: 0.169772\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 14\n",
      "Train Epoch: 14 [0/320 (0%)]\tLoss: 0.103349\n",
      "Train Epoch: 14 [40/320 (12%)]\tLoss: 0.116250\n",
      "Train Epoch: 14 [80/320 (25%)]\tLoss: 0.114624\n",
      "Train Epoch: 14 [120/320 (38%)]\tLoss: 0.113438\n",
      "Train Epoch: 14 [160/320 (50%)]\tLoss: 0.146591\n",
      "Train Epoch: 14 [200/320 (62%)]\tLoss: 0.149064\n",
      "Train Epoch: 14 [240/320 (75%)]\tLoss: 0.117036\n",
      "Train Epoch: 14 [280/320 (88%)]\tLoss: 0.138983\n",
      "\n",
      "Test set: Accuracy: 21/80 (26%)\n",
      "\n",
      "training epoch 15\n",
      "Train Epoch: 15 [0/320 (0%)]\tLoss: 0.148391\n",
      "Train Epoch: 15 [40/320 (12%)]\tLoss: 0.138657\n",
      "Train Epoch: 15 [80/320 (25%)]\tLoss: 0.162175\n",
      "Train Epoch: 15 [120/320 (38%)]\tLoss: 0.141677\n",
      "Train Epoch: 15 [160/320 (50%)]\tLoss: 0.083069\n",
      "Train Epoch: 15 [200/320 (62%)]\tLoss: 0.153043\n",
      "Train Epoch: 15 [240/320 (75%)]\tLoss: 0.094199\n",
      "Train Epoch: 15 [280/320 (88%)]\tLoss: 0.152439\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 16\n",
      "Train Epoch: 16 [0/320 (0%)]\tLoss: 0.165920\n",
      "Train Epoch: 16 [40/320 (12%)]\tLoss: 0.138766\n",
      "Train Epoch: 16 [80/320 (25%)]\tLoss: 0.177793\n",
      "Train Epoch: 16 [120/320 (38%)]\tLoss: 0.140460\n",
      "Train Epoch: 16 [160/320 (50%)]\tLoss: 0.140156\n",
      "Train Epoch: 16 [200/320 (62%)]\tLoss: 0.106299\n",
      "Train Epoch: 16 [240/320 (75%)]\tLoss: 0.153657\n",
      "Train Epoch: 16 [280/320 (88%)]\tLoss: 0.103858\n",
      "\n",
      "Test set: Accuracy: 11/80 (14%)\n",
      "\n",
      "training epoch 17\n",
      "Train Epoch: 17 [0/320 (0%)]\tLoss: 0.152024\n",
      "Train Epoch: 17 [40/320 (12%)]\tLoss: 0.139205\n",
      "Train Epoch: 17 [80/320 (25%)]\tLoss: 0.139676\n",
      "Train Epoch: 17 [120/320 (38%)]\tLoss: 0.089222\n",
      "Train Epoch: 17 [160/320 (50%)]\tLoss: 0.102650\n",
      "Train Epoch: 17 [200/320 (62%)]\tLoss: 0.149349\n",
      "Train Epoch: 17 [240/320 (75%)]\tLoss: 0.120480\n",
      "Train Epoch: 17 [280/320 (88%)]\tLoss: 0.192999\n",
      "\n",
      "Test set: Accuracy: 25/80 (31%)\n",
      "\n",
      "training epoch 18\n",
      "Train Epoch: 18 [0/320 (0%)]\tLoss: 0.117098\n",
      "Train Epoch: 18 [40/320 (12%)]\tLoss: 0.150689\n",
      "Train Epoch: 18 [80/320 (25%)]\tLoss: 0.110619\n",
      "Train Epoch: 18 [120/320 (38%)]\tLoss: 0.126405\n",
      "Train Epoch: 18 [160/320 (50%)]\tLoss: 0.177496\n",
      "Train Epoch: 18 [200/320 (62%)]\tLoss: 0.149360\n",
      "Train Epoch: 18 [240/320 (75%)]\tLoss: 0.158848\n",
      "Train Epoch: 18 [280/320 (88%)]\tLoss: 0.147620\n",
      "\n",
      "Test set: Accuracy: 17/80 (21%)\n",
      "\n",
      "training epoch 19\n",
      "Train Epoch: 19 [0/320 (0%)]\tLoss: 0.088324\n",
      "Train Epoch: 19 [40/320 (12%)]\tLoss: 0.163841\n",
      "Train Epoch: 19 [80/320 (25%)]\tLoss: 0.097446\n",
      "Train Epoch: 19 [120/320 (38%)]\tLoss: 0.155972\n",
      "Train Epoch: 19 [160/320 (50%)]\tLoss: 0.181698\n",
      "Train Epoch: 19 [200/320 (62%)]\tLoss: 0.145539\n",
      "Train Epoch: 19 [240/320 (75%)]\tLoss: 0.120354\n",
      "Train Epoch: 19 [280/320 (88%)]\tLoss: 0.077258\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 20\n",
      "Train Epoch: 20 [0/320 (0%)]\tLoss: 0.150226\n",
      "Train Epoch: 20 [40/320 (12%)]\tLoss: 0.153854\n",
      "Train Epoch: 20 [80/320 (25%)]\tLoss: 0.128766\n",
      "Train Epoch: 20 [120/320 (38%)]\tLoss: 0.100924\n",
      "Train Epoch: 20 [160/320 (50%)]\tLoss: 0.139254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [200/320 (62%)]\tLoss: 0.127817\n",
      "Train Epoch: 20 [240/320 (75%)]\tLoss: 0.105206\n",
      "Train Epoch: 20 [280/320 (88%)]\tLoss: 0.118119\n",
      "\n",
      "Test set: Accuracy: 24/80 (30%)\n",
      "\n",
      "training epoch 21\n",
      "Train Epoch: 21 [0/320 (0%)]\tLoss: 0.120037\n",
      "Train Epoch: 21 [40/320 (12%)]\tLoss: 0.187839\n",
      "Train Epoch: 21 [80/320 (25%)]\tLoss: 0.096697\n",
      "Train Epoch: 21 [120/320 (38%)]\tLoss: 0.168122\n",
      "Train Epoch: 21 [160/320 (50%)]\tLoss: 0.106986\n",
      "Train Epoch: 21 [200/320 (62%)]\tLoss: 0.132516\n",
      "Train Epoch: 21 [240/320 (75%)]\tLoss: 0.094457\n",
      "Train Epoch: 21 [280/320 (88%)]\tLoss: 0.115992\n",
      "\n",
      "Test set: Accuracy: 19/80 (24%)\n",
      "\n",
      "training epoch 22\n",
      "Train Epoch: 22 [0/320 (0%)]\tLoss: 0.114777\n",
      "Train Epoch: 22 [40/320 (12%)]\tLoss: 0.126823\n",
      "Train Epoch: 22 [80/320 (25%)]\tLoss: 0.130811\n",
      "Train Epoch: 22 [120/320 (38%)]\tLoss: 0.103881\n",
      "Train Epoch: 22 [160/320 (50%)]\tLoss: 0.136740\n",
      "Train Epoch: 22 [200/320 (62%)]\tLoss: 0.145961\n",
      "Train Epoch: 22 [240/320 (75%)]\tLoss: 0.172568\n",
      "Train Epoch: 22 [280/320 (88%)]\tLoss: 0.130506\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 23\n",
      "Train Epoch: 23 [0/320 (0%)]\tLoss: 0.100821\n",
      "Train Epoch: 23 [40/320 (12%)]\tLoss: 0.134531\n",
      "Train Epoch: 23 [80/320 (25%)]\tLoss: 0.131107\n",
      "Train Epoch: 23 [120/320 (38%)]\tLoss: 0.136765\n",
      "Train Epoch: 23 [160/320 (50%)]\tLoss: 0.118235\n",
      "Train Epoch: 23 [200/320 (62%)]\tLoss: 0.073518\n",
      "Train Epoch: 23 [240/320 (75%)]\tLoss: 0.126337\n",
      "Train Epoch: 23 [280/320 (88%)]\tLoss: 0.081607\n",
      "\n",
      "Test set: Accuracy: 17/80 (21%)\n",
      "\n",
      "training epoch 24\n",
      "Train Epoch: 24 [0/320 (0%)]\tLoss: 0.124856\n",
      "Train Epoch: 24 [40/320 (12%)]\tLoss: 0.098437\n",
      "Train Epoch: 24 [80/320 (25%)]\tLoss: 0.085299\n",
      "Train Epoch: 24 [120/320 (38%)]\tLoss: 0.076571\n",
      "Train Epoch: 24 [160/320 (50%)]\tLoss: 0.105946\n",
      "Train Epoch: 24 [200/320 (62%)]\tLoss: 0.086284\n",
      "Train Epoch: 24 [240/320 (75%)]\tLoss: 0.131291\n",
      "Train Epoch: 24 [280/320 (88%)]\tLoss: 0.150590\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 25\n",
      "Train Epoch: 25 [0/320 (0%)]\tLoss: 0.063574\n",
      "Train Epoch: 25 [40/320 (12%)]\tLoss: 0.131945\n",
      "Train Epoch: 25 [80/320 (25%)]\tLoss: 0.121437\n",
      "Train Epoch: 25 [120/320 (38%)]\tLoss: 0.087633\n",
      "Train Epoch: 25 [160/320 (50%)]\tLoss: 0.092423\n",
      "Train Epoch: 25 [200/320 (62%)]\tLoss: 0.134005\n",
      "Train Epoch: 25 [240/320 (75%)]\tLoss: 0.086463\n",
      "Train Epoch: 25 [280/320 (88%)]\tLoss: 0.203147\n",
      "\n",
      "Test set: Accuracy: 17/80 (21%)\n",
      "\n",
      "training epoch 26\n",
      "Train Epoch: 26 [0/320 (0%)]\tLoss: 0.101273\n",
      "Train Epoch: 26 [40/320 (12%)]\tLoss: 0.095004\n",
      "Train Epoch: 26 [80/320 (25%)]\tLoss: 0.124726\n",
      "Train Epoch: 26 [120/320 (38%)]\tLoss: 0.080743\n",
      "Train Epoch: 26 [160/320 (50%)]\tLoss: 0.131130\n",
      "Train Epoch: 26 [200/320 (62%)]\tLoss: 0.119825\n",
      "Train Epoch: 26 [240/320 (75%)]\tLoss: 0.149562\n",
      "Train Epoch: 26 [280/320 (88%)]\tLoss: 0.055436\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 27\n",
      "Train Epoch: 27 [0/320 (0%)]\tLoss: 0.093105\n",
      "Train Epoch: 27 [40/320 (12%)]\tLoss: 0.142004\n",
      "Train Epoch: 27 [80/320 (25%)]\tLoss: 0.110867\n",
      "Train Epoch: 27 [120/320 (38%)]\tLoss: 0.092529\n",
      "Train Epoch: 27 [160/320 (50%)]\tLoss: 0.119568\n",
      "Train Epoch: 27 [200/320 (62%)]\tLoss: 0.123875\n",
      "Train Epoch: 27 [240/320 (75%)]\tLoss: 0.107157\n",
      "Train Epoch: 27 [280/320 (88%)]\tLoss: 0.124114\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 28\n",
      "Train Epoch: 28 [0/320 (0%)]\tLoss: 0.119543\n",
      "Train Epoch: 28 [40/320 (12%)]\tLoss: 0.093044\n",
      "Train Epoch: 28 [80/320 (25%)]\tLoss: 0.105645\n",
      "Train Epoch: 28 [120/320 (38%)]\tLoss: 0.123448\n",
      "Train Epoch: 28 [160/320 (50%)]\tLoss: 0.129895\n",
      "Train Epoch: 28 [200/320 (62%)]\tLoss: 0.087102\n",
      "Train Epoch: 28 [240/320 (75%)]\tLoss: 0.077670\n",
      "Train Epoch: 28 [280/320 (88%)]\tLoss: 0.121020\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 29\n",
      "Train Epoch: 29 [0/320 (0%)]\tLoss: 0.072102\n",
      "Train Epoch: 29 [40/320 (12%)]\tLoss: 0.114690\n",
      "Train Epoch: 29 [80/320 (25%)]\tLoss: 0.095350\n",
      "Train Epoch: 29 [120/320 (38%)]\tLoss: 0.138868\n",
      "Train Epoch: 29 [160/320 (50%)]\tLoss: 0.120218\n",
      "Train Epoch: 29 [200/320 (62%)]\tLoss: 0.127246\n",
      "Train Epoch: 29 [240/320 (75%)]\tLoss: 0.117928\n",
      "Train Epoch: 29 [280/320 (88%)]\tLoss: 0.159421\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 30\n",
      "Train Epoch: 30 [0/320 (0%)]\tLoss: 0.148450\n",
      "Train Epoch: 30 [40/320 (12%)]\tLoss: 0.087200\n",
      "Train Epoch: 30 [80/320 (25%)]\tLoss: 0.100828\n",
      "Train Epoch: 30 [120/320 (38%)]\tLoss: 0.094036\n",
      "Train Epoch: 30 [160/320 (50%)]\tLoss: 0.089926\n",
      "Train Epoch: 30 [200/320 (62%)]\tLoss: 0.123016\n",
      "Train Epoch: 30 [240/320 (75%)]\tLoss: 0.126183\n",
      "Train Epoch: 30 [280/320 (88%)]\tLoss: 0.107396\n",
      "\n",
      "Test set: Accuracy: 19/80 (24%)\n",
      "\n",
      "training epoch 31\n",
      "First round of training complete. Setting learn rate to 0.001.\n",
      "Train Epoch: 31 [0/320 (0%)]\tLoss: 0.083259\n",
      "Train Epoch: 31 [40/320 (12%)]\tLoss: 0.062693\n",
      "Train Epoch: 31 [80/320 (25%)]\tLoss: 0.078890\n",
      "Train Epoch: 31 [120/320 (38%)]\tLoss: 0.097783\n",
      "Train Epoch: 31 [160/320 (50%)]\tLoss: 0.088833\n",
      "Train Epoch: 31 [200/320 (62%)]\tLoss: 0.113451\n",
      "Train Epoch: 31 [240/320 (75%)]\tLoss: 0.130477\n",
      "Train Epoch: 31 [280/320 (88%)]\tLoss: 0.106659\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 32\n",
      "Train Epoch: 32 [0/320 (0%)]\tLoss: 0.143122\n",
      "Train Epoch: 32 [40/320 (12%)]\tLoss: 0.107261\n",
      "Train Epoch: 32 [80/320 (25%)]\tLoss: 0.104706\n",
      "Train Epoch: 32 [120/320 (38%)]\tLoss: 0.094063\n",
      "Train Epoch: 32 [160/320 (50%)]\tLoss: 0.086028\n",
      "Train Epoch: 32 [200/320 (62%)]\tLoss: 0.146258\n",
      "Train Epoch: 32 [240/320 (75%)]\tLoss: 0.153469\n",
      "Train Epoch: 32 [280/320 (88%)]\tLoss: 0.089463\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 33\n",
      "Train Epoch: 33 [0/320 (0%)]\tLoss: 0.117592\n",
      "Train Epoch: 33 [40/320 (12%)]\tLoss: 0.102590\n",
      "Train Epoch: 33 [80/320 (25%)]\tLoss: 0.111098\n"
     ]
    }
   ],
   "source": [
    "#ORIGINAL\n",
    "import warnings\n",
    "\n",
    "log_interval = 5\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for epoch in range(1, 41):\n",
    "    print(\"training epoch \" + str(epoch))\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "#     scheduler.step()\n",
    "    train(model, epoch)\n",
    "    scheduler.step()\n",
    "    test(model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "\n",
    "below is the mfccs notes / random code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "torch.save(model.state_dict(), 'dataset_model_soundemotion.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio, sample_rate = librosa.load(\"SongEmotionDataset/1.mp3\", res_type='kaiser_fast')\n",
    "# # [print(x) for x in audio]\n",
    "\n",
    "# #convert audio into 2d array\n",
    "# mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "# # mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "# print(mfccs.shape, audio.shape)\n",
    "# mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_tensor = torch.tensor(audio)\n",
    "# audio_tensor\n",
    "# audio_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sound_file in data_path.iterdir():\n",
    "#     if \".mp3\" in str(sound_file):\n",
    "#         print(sound_file)\n",
    "#         audio, sample_rate = librosa.load(str(sound_file), res_type='kaiser_fast')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
