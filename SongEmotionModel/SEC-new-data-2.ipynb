{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import decorators\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "song_to_label = {}\n",
    "\n",
    "path = \"otherdata/songs/\"\n",
    "\n",
    "with open('otherdata/mark.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        \n",
    "        raw_scores = [int(raw) for raw in row[3].split('_')]\n",
    "        score = (raw_scores[0]*-1 + raw_scores[2]) / (raw_scores[0] + raw_scores[1] + raw_scores[2])\n",
    "        \n",
    "        song_to_label[path + row[0] + \".m4a\"] = score\n",
    "        \n",
    "songs = list(song_to_label.keys())\n",
    "labels = list(song_to_label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percentage = 0.8\n",
    "\n",
    "index = round(len(songs)*train_percentage)\n",
    "\n",
    "train_songs = songs[:index]\n",
    "test_songs = songs[index:]\n",
    "\n",
    "train_labels = labels[:index]\n",
    "test_labels = labels[index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongEmotionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Song Emotion Dataset. Uses librosa to process mp3 files.\n",
    "    Takes first 20 seconds, and samples every 10 to get processed audio tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, songs, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mp3: list of paths to mp3 files\n",
    "            labels: list of labels\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.songs = songs\n",
    "        self.cache = {}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index not in self.cache.keys():\n",
    "#             print(\"index of \" + str(index) + \" was cached!\")\n",
    "            data, rate = librosa.load(self.songs[index], sr=16000, duration=10)\n",
    "            assert rate == 16000\n",
    "            sample_tensor = torch.tensor(data, device=device).float()\n",
    "            downsampled_tensor = sample_tensor[::10]\n",
    "\n",
    "            self.cache[index] = (downsampled_tensor, F.softmax(self.labels[index]))\n",
    "            \n",
    "        return self.cache[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 128, kernel_size=(80,), stride=(4,))\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgPool): AvgPool1d(kernel_size=(14,), stride=(14,), padding=(0,))\n",
      "  (fc1): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 128, 80, 4)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(128, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(256, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.avgPool = nn.AvgPool1d(14) #input should be 512x30 so this outputs a 512x1\n",
    "        self.fc1 = nn.Linear(512, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim = 2)\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 3327\n",
      "Test set size: 832\n"
     ]
    }
   ],
   "source": [
    "train_set = SongEmotionDataset(train_songs, train_labels)\n",
    "test_set = SongEmotionDataset(test_songs, test_labels)\n",
    "print(\"Train set size: \" + str(len(train_set)))\n",
    "print(\"Test set size: \" + str(len(test_set)))\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {} #needed for using datasets on gpu\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 8, shuffle = True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 8, shuffle = True, **kwargs)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data.unsqueeze_(1)\n",
    "        data = data.requires_grad_() #set requires_grad to True for training\n",
    "        output = model(data)\n",
    "        output = output.view(-1, len(emotions))\n",
    "#         print(output.shape, target.shape)\n",
    "#         print(output, target)\n",
    "        loss = F.kl_div(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         scheduler.step()\n",
    "        if batch_idx % log_interval == 0: #print training stats\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data.unsqueeze_(1)\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        pred = output.max(2)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.max(1)[1]).cpu().sum().item()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'otherdata/songs/TRAUXNG128F933AA28.m4a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0;32m-> 1184\u001b[0;31m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening 'otherdata/songs/TRAUXNG128F933AA28.m4a': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-27ba7d217a18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First round of training complete. Setting learn rate to 0.001.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-388c69c395bf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-17ec0370c885>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#             print(\"index of \" + str(index) + \" was cached!\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msongs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0msample_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PySoundFile failed. Trying audioread instead.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memories/myenv/lib/python3.6/site-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'otherdata/songs/TRAUXNG128F933AA28.m4a'"
     ]
    }
   ],
   "source": [
    "#w caching & data processing\n",
    "import warnings\n",
    "\n",
    "log_interval = 5\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for epoch in range(1, 41):\n",
    "    print(\"training epoch \" + str(epoch))\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "#     scheduler.step()\n",
    "    train(model, epoch)\n",
    "    scheduler.step()\n",
    "    test(model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1\n",
      "Train Epoch: 1 [0/320 (0%)]\tLoss: 0.191720\n",
      "Train Epoch: 1 [40/320 (12%)]\tLoss: 0.329261\n",
      "Train Epoch: 1 [80/320 (25%)]\tLoss: 0.284903\n",
      "Train Epoch: 1 [120/320 (38%)]\tLoss: 0.338861\n",
      "Train Epoch: 1 [160/320 (50%)]\tLoss: 0.210636\n",
      "Train Epoch: 1 [200/320 (62%)]\tLoss: 0.167495\n",
      "Train Epoch: 1 [240/320 (75%)]\tLoss: 0.162565\n",
      "Train Epoch: 1 [280/320 (88%)]\tLoss: 0.321939\n",
      "\n",
      "Test set: Accuracy: 19/80 (24%)\n",
      "\n",
      "training epoch 2\n",
      "Train Epoch: 2 [0/320 (0%)]\tLoss: 0.210194\n",
      "Train Epoch: 2 [40/320 (12%)]\tLoss: 0.201684\n",
      "Train Epoch: 2 [80/320 (25%)]\tLoss: 0.117230\n",
      "Train Epoch: 2 [120/320 (38%)]\tLoss: 0.207198\n",
      "Train Epoch: 2 [160/320 (50%)]\tLoss: 0.188115\n",
      "Train Epoch: 2 [200/320 (62%)]\tLoss: 0.190015\n",
      "Train Epoch: 2 [240/320 (75%)]\tLoss: 0.140593\n",
      "Train Epoch: 2 [280/320 (88%)]\tLoss: 0.213586\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 3\n",
      "Train Epoch: 3 [0/320 (0%)]\tLoss: 0.127676\n",
      "Train Epoch: 3 [40/320 (12%)]\tLoss: 0.175529\n",
      "Train Epoch: 3 [80/320 (25%)]\tLoss: 0.160134\n",
      "Train Epoch: 3 [120/320 (38%)]\tLoss: 0.157589\n",
      "Train Epoch: 3 [160/320 (50%)]\tLoss: 0.168349\n",
      "Train Epoch: 3 [200/320 (62%)]\tLoss: 0.149061\n",
      "Train Epoch: 3 [240/320 (75%)]\tLoss: 0.154252\n",
      "Train Epoch: 3 [280/320 (88%)]\tLoss: 0.180634\n",
      "\n",
      "Test set: Accuracy: 23/80 (29%)\n",
      "\n",
      "training epoch 4\n",
      "Train Epoch: 4 [0/320 (0%)]\tLoss: 0.153863\n",
      "Train Epoch: 4 [40/320 (12%)]\tLoss: 0.170401\n",
      "Train Epoch: 4 [80/320 (25%)]\tLoss: 0.116388\n",
      "Train Epoch: 4 [120/320 (38%)]\tLoss: 0.124060\n",
      "Train Epoch: 4 [160/320 (50%)]\tLoss: 0.143214\n",
      "Train Epoch: 4 [200/320 (62%)]\tLoss: 0.179630\n",
      "Train Epoch: 4 [240/320 (75%)]\tLoss: 0.188496\n",
      "Train Epoch: 4 [280/320 (88%)]\tLoss: 0.182668\n",
      "\n",
      "Test set: Accuracy: 23/80 (29%)\n",
      "\n",
      "training epoch 5\n",
      "Train Epoch: 5 [0/320 (0%)]\tLoss: 0.146198\n",
      "Train Epoch: 5 [40/320 (12%)]\tLoss: 0.151484\n",
      "Train Epoch: 5 [80/320 (25%)]\tLoss: 0.144369\n",
      "Train Epoch: 5 [120/320 (38%)]\tLoss: 0.135824\n",
      "Train Epoch: 5 [160/320 (50%)]\tLoss: 0.147213\n",
      "Train Epoch: 5 [200/320 (62%)]\tLoss: 0.169771\n",
      "Train Epoch: 5 [240/320 (75%)]\tLoss: 0.166857\n",
      "Train Epoch: 5 [280/320 (88%)]\tLoss: 0.110782\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 6\n",
      "Train Epoch: 6 [0/320 (0%)]\tLoss: 0.148035\n",
      "Train Epoch: 6 [40/320 (12%)]\tLoss: 0.132011\n",
      "Train Epoch: 6 [80/320 (25%)]\tLoss: 0.172618\n",
      "Train Epoch: 6 [120/320 (38%)]\tLoss: 0.164004\n",
      "Train Epoch: 6 [160/320 (50%)]\tLoss: 0.099142\n",
      "Train Epoch: 6 [200/320 (62%)]\tLoss: 0.131375\n",
      "Train Epoch: 6 [240/320 (75%)]\tLoss: 0.168143\n",
      "Train Epoch: 6 [280/320 (88%)]\tLoss: 0.174055\n",
      "\n",
      "Test set: Accuracy: 22/80 (28%)\n",
      "\n",
      "training epoch 7\n",
      "Train Epoch: 7 [0/320 (0%)]\tLoss: 0.105413\n",
      "Train Epoch: 7 [40/320 (12%)]\tLoss: 0.137166\n",
      "Train Epoch: 7 [80/320 (25%)]\tLoss: 0.142146\n",
      "Train Epoch: 7 [120/320 (38%)]\tLoss: 0.193170\n",
      "Train Epoch: 7 [160/320 (50%)]\tLoss: 0.148268\n",
      "Train Epoch: 7 [200/320 (62%)]\tLoss: 0.143546\n",
      "Train Epoch: 7 [240/320 (75%)]\tLoss: 0.133050\n",
      "Train Epoch: 7 [280/320 (88%)]\tLoss: 0.134236\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 8\n",
      "Train Epoch: 8 [0/320 (0%)]\tLoss: 0.128067\n",
      "Train Epoch: 8 [40/320 (12%)]\tLoss: 0.138545\n",
      "Train Epoch: 8 [80/320 (25%)]\tLoss: 0.158826\n",
      "Train Epoch: 8 [120/320 (38%)]\tLoss: 0.131687\n",
      "Train Epoch: 8 [160/320 (50%)]\tLoss: 0.187674\n",
      "Train Epoch: 8 [200/320 (62%)]\tLoss: 0.121796\n",
      "Train Epoch: 8 [240/320 (75%)]\tLoss: 0.147160\n",
      "Train Epoch: 8 [280/320 (88%)]\tLoss: 0.203417\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 9\n",
      "Train Epoch: 9 [0/320 (0%)]\tLoss: 0.164306\n",
      "Train Epoch: 9 [40/320 (12%)]\tLoss: 0.165597\n",
      "Train Epoch: 9 [80/320 (25%)]\tLoss: 0.122330\n",
      "Train Epoch: 9 [120/320 (38%)]\tLoss: 0.111132\n",
      "Train Epoch: 9 [160/320 (50%)]\tLoss: 0.127811\n",
      "Train Epoch: 9 [200/320 (62%)]\tLoss: 0.131876\n",
      "Train Epoch: 9 [240/320 (75%)]\tLoss: 0.117554\n",
      "Train Epoch: 9 [280/320 (88%)]\tLoss: 0.151157\n",
      "\n",
      "Test set: Accuracy: 23/80 (29%)\n",
      "\n",
      "training epoch 10\n",
      "Train Epoch: 10 [0/320 (0%)]\tLoss: 0.147492\n",
      "Train Epoch: 10 [40/320 (12%)]\tLoss: 0.136711\n",
      "Train Epoch: 10 [80/320 (25%)]\tLoss: 0.158314\n",
      "Train Epoch: 10 [120/320 (38%)]\tLoss: 0.119198\n",
      "Train Epoch: 10 [160/320 (50%)]\tLoss: 0.118704\n",
      "Train Epoch: 10 [200/320 (62%)]\tLoss: 0.153009\n",
      "Train Epoch: 10 [240/320 (75%)]\tLoss: 0.189993\n",
      "Train Epoch: 10 [280/320 (88%)]\tLoss: 0.132757\n",
      "\n",
      "Test set: Accuracy: 24/80 (30%)\n",
      "\n",
      "training epoch 11\n",
      "Train Epoch: 11 [0/320 (0%)]\tLoss: 0.148846\n",
      "Train Epoch: 11 [40/320 (12%)]\tLoss: 0.139574\n",
      "Train Epoch: 11 [80/320 (25%)]\tLoss: 0.160432\n",
      "Train Epoch: 11 [120/320 (38%)]\tLoss: 0.174024\n",
      "Train Epoch: 11 [160/320 (50%)]\tLoss: 0.161915\n",
      "Train Epoch: 11 [200/320 (62%)]\tLoss: 0.110037\n",
      "Train Epoch: 11 [240/320 (75%)]\tLoss: 0.162453\n",
      "Train Epoch: 11 [280/320 (88%)]\tLoss: 0.139737\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 12\n",
      "Train Epoch: 12 [0/320 (0%)]\tLoss: 0.150581\n",
      "Train Epoch: 12 [40/320 (12%)]\tLoss: 0.166083\n",
      "Train Epoch: 12 [80/320 (25%)]\tLoss: 0.152030\n",
      "Train Epoch: 12 [120/320 (38%)]\tLoss: 0.161329\n",
      "Train Epoch: 12 [160/320 (50%)]\tLoss: 0.164096\n",
      "Train Epoch: 12 [200/320 (62%)]\tLoss: 0.144470\n",
      "Train Epoch: 12 [240/320 (75%)]\tLoss: 0.114608\n",
      "Train Epoch: 12 [280/320 (88%)]\tLoss: 0.144294\n",
      "\n",
      "Test set: Accuracy: 24/80 (30%)\n",
      "\n",
      "training epoch 13\n",
      "Train Epoch: 13 [0/320 (0%)]\tLoss: 0.150582\n",
      "Train Epoch: 13 [40/320 (12%)]\tLoss: 0.119003\n",
      "Train Epoch: 13 [80/320 (25%)]\tLoss: 0.137122\n",
      "Train Epoch: 13 [120/320 (38%)]\tLoss: 0.130961\n",
      "Train Epoch: 13 [160/320 (50%)]\tLoss: 0.140995\n",
      "Train Epoch: 13 [200/320 (62%)]\tLoss: 0.139647\n",
      "Train Epoch: 13 [240/320 (75%)]\tLoss: 0.129678\n",
      "Train Epoch: 13 [280/320 (88%)]\tLoss: 0.138817\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 14\n",
      "Train Epoch: 14 [0/320 (0%)]\tLoss: 0.168014\n",
      "Train Epoch: 14 [40/320 (12%)]\tLoss: 0.119383\n",
      "Train Epoch: 14 [80/320 (25%)]\tLoss: 0.211341\n",
      "Train Epoch: 14 [120/320 (38%)]\tLoss: 0.121242\n",
      "Train Epoch: 14 [160/320 (50%)]\tLoss: 0.120812\n",
      "Train Epoch: 14 [200/320 (62%)]\tLoss: 0.144962\n",
      "Train Epoch: 14 [240/320 (75%)]\tLoss: 0.123729\n",
      "Train Epoch: 14 [280/320 (88%)]\tLoss: 0.118727\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 15\n",
      "Train Epoch: 15 [0/320 (0%)]\tLoss: 0.115412\n",
      "Train Epoch: 15 [40/320 (12%)]\tLoss: 0.188811\n",
      "Train Epoch: 15 [80/320 (25%)]\tLoss: 0.128344\n",
      "Train Epoch: 15 [120/320 (38%)]\tLoss: 0.149197\n",
      "Train Epoch: 15 [160/320 (50%)]\tLoss: 0.103601\n",
      "Train Epoch: 15 [200/320 (62%)]\tLoss: 0.143465\n",
      "Train Epoch: 15 [240/320 (75%)]\tLoss: 0.162857\n",
      "Train Epoch: 15 [280/320 (88%)]\tLoss: 0.169206\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 16\n",
      "Train Epoch: 16 [0/320 (0%)]\tLoss: 0.144088\n",
      "Train Epoch: 16 [40/320 (12%)]\tLoss: 0.130324\n",
      "Train Epoch: 16 [80/320 (25%)]\tLoss: 0.147940\n",
      "Train Epoch: 16 [120/320 (38%)]\tLoss: 0.138095\n",
      "Train Epoch: 16 [160/320 (50%)]\tLoss: 0.109504\n",
      "Train Epoch: 16 [200/320 (62%)]\tLoss: 0.160420\n",
      "Train Epoch: 16 [240/320 (75%)]\tLoss: 0.167246\n",
      "Train Epoch: 16 [280/320 (88%)]\tLoss: 0.142288\n",
      "\n",
      "Test set: Accuracy: 24/80 (30%)\n",
      "\n",
      "training epoch 17\n",
      "Train Epoch: 17 [0/320 (0%)]\tLoss: 0.140414\n",
      "Train Epoch: 17 [40/320 (12%)]\tLoss: 0.148044\n",
      "Train Epoch: 17 [80/320 (25%)]\tLoss: 0.117693\n",
      "Train Epoch: 17 [120/320 (38%)]\tLoss: 0.143165\n",
      "Train Epoch: 17 [160/320 (50%)]\tLoss: 0.140589\n",
      "Train Epoch: 17 [200/320 (62%)]\tLoss: 0.172596\n",
      "Train Epoch: 17 [240/320 (75%)]\tLoss: 0.129349\n",
      "Train Epoch: 17 [280/320 (88%)]\tLoss: 0.117940\n",
      "\n",
      "Test set: Accuracy: 31/80 (39%)\n",
      "\n",
      "training epoch 18\n",
      "Train Epoch: 18 [0/320 (0%)]\tLoss: 0.119135\n",
      "Train Epoch: 18 [40/320 (12%)]\tLoss: 0.190739\n",
      "Train Epoch: 18 [80/320 (25%)]\tLoss: 0.161680\n",
      "Train Epoch: 18 [120/320 (38%)]\tLoss: 0.132813\n",
      "Train Epoch: 18 [160/320 (50%)]\tLoss: 0.171426\n",
      "Train Epoch: 18 [200/320 (62%)]\tLoss: 0.135142\n",
      "Train Epoch: 18 [240/320 (75%)]\tLoss: 0.155324\n",
      "Train Epoch: 18 [280/320 (88%)]\tLoss: 0.137221\n",
      "\n",
      "Test set: Accuracy: 21/80 (26%)\n",
      "\n",
      "training epoch 19\n",
      "Train Epoch: 19 [0/320 (0%)]\tLoss: 0.126812\n",
      "Train Epoch: 19 [40/320 (12%)]\tLoss: 0.154804\n",
      "Train Epoch: 19 [80/320 (25%)]\tLoss: 0.110585\n",
      "Train Epoch: 19 [120/320 (38%)]\tLoss: 0.136034\n",
      "Train Epoch: 19 [160/320 (50%)]\tLoss: 0.124886\n",
      "Train Epoch: 19 [200/320 (62%)]\tLoss: 0.148867\n",
      "Train Epoch: 19 [240/320 (75%)]\tLoss: 0.123274\n",
      "Train Epoch: 19 [280/320 (88%)]\tLoss: 0.120195\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n",
      "training epoch 20\n",
      "Train Epoch: 20 [0/320 (0%)]\tLoss: 0.119467\n",
      "Train Epoch: 20 [40/320 (12%)]\tLoss: 0.129316\n",
      "Train Epoch: 20 [80/320 (25%)]\tLoss: 0.101322\n",
      "Train Epoch: 20 [120/320 (38%)]\tLoss: 0.098406\n",
      "Train Epoch: 20 [160/320 (50%)]\tLoss: 0.128697\n",
      "Train Epoch: 20 [200/320 (62%)]\tLoss: 0.160592\n",
      "Train Epoch: 20 [240/320 (75%)]\tLoss: 0.123497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [280/320 (88%)]\tLoss: 0.164417\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n",
      "training epoch 21\n",
      "Train Epoch: 21 [0/320 (0%)]\tLoss: 0.088417\n",
      "Train Epoch: 21 [40/320 (12%)]\tLoss: 0.127397\n",
      "Train Epoch: 21 [80/320 (25%)]\tLoss: 0.162288\n",
      "Train Epoch: 21 [120/320 (38%)]\tLoss: 0.132321\n",
      "Train Epoch: 21 [160/320 (50%)]\tLoss: 0.123884\n",
      "Train Epoch: 21 [200/320 (62%)]\tLoss: 0.132901\n",
      "Train Epoch: 21 [240/320 (75%)]\tLoss: 0.092551\n",
      "Train Epoch: 21 [280/320 (88%)]\tLoss: 0.152662\n",
      "\n",
      "Test set: Accuracy: 29/80 (36%)\n",
      "\n",
      "training epoch 22\n",
      "Train Epoch: 22 [0/320 (0%)]\tLoss: 0.099070\n",
      "Train Epoch: 22 [40/320 (12%)]\tLoss: 0.107604\n",
      "Train Epoch: 22 [80/320 (25%)]\tLoss: 0.164107\n",
      "Train Epoch: 22 [120/320 (38%)]\tLoss: 0.155712\n",
      "Train Epoch: 22 [160/320 (50%)]\tLoss: 0.088193\n",
      "Train Epoch: 22 [200/320 (62%)]\tLoss: 0.099478\n",
      "Train Epoch: 22 [240/320 (75%)]\tLoss: 0.130642\n",
      "Train Epoch: 22 [280/320 (88%)]\tLoss: 0.101703\n",
      "\n",
      "Test set: Accuracy: 29/80 (36%)\n",
      "\n",
      "training epoch 23\n",
      "Train Epoch: 23 [0/320 (0%)]\tLoss: 0.141142\n",
      "Train Epoch: 23 [40/320 (12%)]\tLoss: 0.086931\n",
      "Train Epoch: 23 [80/320 (25%)]\tLoss: 0.119440\n",
      "Train Epoch: 23 [120/320 (38%)]\tLoss: 0.134644\n",
      "Train Epoch: 23 [160/320 (50%)]\tLoss: 0.090799\n",
      "Train Epoch: 23 [200/320 (62%)]\tLoss: 0.103606\n",
      "Train Epoch: 23 [240/320 (75%)]\tLoss: 0.155308\n",
      "Train Epoch: 23 [280/320 (88%)]\tLoss: 0.107537\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n",
      "training epoch 24\n",
      "Train Epoch: 24 [0/320 (0%)]\tLoss: 0.121201\n",
      "Train Epoch: 24 [40/320 (12%)]\tLoss: 0.141290\n",
      "Train Epoch: 24 [80/320 (25%)]\tLoss: 0.117531\n",
      "Train Epoch: 24 [120/320 (38%)]\tLoss: 0.123993\n",
      "Train Epoch: 24 [160/320 (50%)]\tLoss: 0.147009\n",
      "Train Epoch: 24 [200/320 (62%)]\tLoss: 0.087602\n",
      "Train Epoch: 24 [240/320 (75%)]\tLoss: 0.129175\n",
      "Train Epoch: 24 [280/320 (88%)]\tLoss: 0.149384\n",
      "\n",
      "Test set: Accuracy: 29/80 (36%)\n",
      "\n",
      "training epoch 25\n",
      "Train Epoch: 25 [0/320 (0%)]\tLoss: 0.127346\n",
      "Train Epoch: 25 [40/320 (12%)]\tLoss: 0.087091\n",
      "Train Epoch: 25 [80/320 (25%)]\tLoss: 0.113754\n",
      "Train Epoch: 25 [120/320 (38%)]\tLoss: 0.115145\n",
      "Train Epoch: 25 [160/320 (50%)]\tLoss: 0.066550\n",
      "Train Epoch: 25 [200/320 (62%)]\tLoss: 0.125560\n",
      "Train Epoch: 25 [240/320 (75%)]\tLoss: 0.117185\n",
      "Train Epoch: 25 [280/320 (88%)]\tLoss: 0.107832\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 26\n",
      "Train Epoch: 26 [0/320 (0%)]\tLoss: 0.090539\n",
      "Train Epoch: 26 [40/320 (12%)]\tLoss: 0.071152\n",
      "Train Epoch: 26 [80/320 (25%)]\tLoss: 0.082525\n",
      "Train Epoch: 26 [120/320 (38%)]\tLoss: 0.138505\n",
      "Train Epoch: 26 [160/320 (50%)]\tLoss: 0.139483\n",
      "Train Epoch: 26 [200/320 (62%)]\tLoss: 0.173734\n",
      "Train Epoch: 26 [240/320 (75%)]\tLoss: 0.096552\n",
      "Train Epoch: 26 [280/320 (88%)]\tLoss: 0.112132\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 27\n",
      "Train Epoch: 27 [0/320 (0%)]\tLoss: 0.114917\n",
      "Train Epoch: 27 [40/320 (12%)]\tLoss: 0.126686\n",
      "Train Epoch: 27 [80/320 (25%)]\tLoss: 0.118474\n",
      "Train Epoch: 27 [120/320 (38%)]\tLoss: 0.148894\n",
      "Train Epoch: 27 [160/320 (50%)]\tLoss: 0.089145\n",
      "Train Epoch: 27 [200/320 (62%)]\tLoss: 0.130509\n",
      "Train Epoch: 27 [240/320 (75%)]\tLoss: 0.126584\n",
      "Train Epoch: 27 [280/320 (88%)]\tLoss: 0.069998\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n",
      "training epoch 28\n",
      "Train Epoch: 28 [0/320 (0%)]\tLoss: 0.109808\n",
      "Train Epoch: 28 [40/320 (12%)]\tLoss: 0.088457\n",
      "Train Epoch: 28 [80/320 (25%)]\tLoss: 0.116812\n",
      "Train Epoch: 28 [120/320 (38%)]\tLoss: 0.101893\n",
      "Train Epoch: 28 [160/320 (50%)]\tLoss: 0.101277\n",
      "Train Epoch: 28 [200/320 (62%)]\tLoss: 0.109269\n",
      "Train Epoch: 28 [240/320 (75%)]\tLoss: 0.061327\n",
      "Train Epoch: 28 [280/320 (88%)]\tLoss: 0.102560\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 29\n",
      "Train Epoch: 29 [0/320 (0%)]\tLoss: 0.075848\n",
      "Train Epoch: 29 [40/320 (12%)]\tLoss: 0.091220\n",
      "Train Epoch: 29 [80/320 (25%)]\tLoss: 0.086960\n",
      "Train Epoch: 29 [120/320 (38%)]\tLoss: 0.090697\n",
      "Train Epoch: 29 [160/320 (50%)]\tLoss: 0.088046\n",
      "Train Epoch: 29 [200/320 (62%)]\tLoss: 0.123191\n",
      "Train Epoch: 29 [240/320 (75%)]\tLoss: 0.098705\n",
      "Train Epoch: 29 [280/320 (88%)]\tLoss: 0.097021\n",
      "\n",
      "Test set: Accuracy: 31/80 (39%)\n",
      "\n",
      "training epoch 30\n",
      "Train Epoch: 30 [0/320 (0%)]\tLoss: 0.113539\n",
      "Train Epoch: 30 [40/320 (12%)]\tLoss: 0.132801\n",
      "Train Epoch: 30 [80/320 (25%)]\tLoss: 0.100028\n",
      "Train Epoch: 30 [120/320 (38%)]\tLoss: 0.075523\n",
      "Train Epoch: 30 [160/320 (50%)]\tLoss: 0.115936\n",
      "Train Epoch: 30 [200/320 (62%)]\tLoss: 0.087016\n",
      "Train Epoch: 30 [240/320 (75%)]\tLoss: 0.114637\n",
      "Train Epoch: 30 [280/320 (88%)]\tLoss: 0.123242\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 31\n",
      "First round of training complete. Setting learn rate to 0.001.\n",
      "Train Epoch: 31 [0/320 (0%)]\tLoss: 0.162124\n",
      "Train Epoch: 31 [40/320 (12%)]\tLoss: 0.130128\n",
      "Train Epoch: 31 [80/320 (25%)]\tLoss: 0.098175\n",
      "Train Epoch: 31 [120/320 (38%)]\tLoss: 0.094875\n",
      "Train Epoch: 31 [160/320 (50%)]\tLoss: 0.104179\n",
      "Train Epoch: 31 [200/320 (62%)]\tLoss: 0.123220\n",
      "Train Epoch: 31 [240/320 (75%)]\tLoss: 0.077964\n",
      "Train Epoch: 31 [280/320 (88%)]\tLoss: 0.096107\n",
      "\n",
      "Test set: Accuracy: 26/80 (32%)\n",
      "\n",
      "training epoch 32\n",
      "Train Epoch: 32 [0/320 (0%)]\tLoss: 0.100305\n",
      "Train Epoch: 32 [40/320 (12%)]\tLoss: 0.076191\n",
      "Train Epoch: 32 [80/320 (25%)]\tLoss: 0.116749\n",
      "Train Epoch: 32 [120/320 (38%)]\tLoss: 0.117503\n",
      "Train Epoch: 32 [160/320 (50%)]\tLoss: 0.124027\n",
      "Train Epoch: 32 [200/320 (62%)]\tLoss: 0.114248\n",
      "Train Epoch: 32 [240/320 (75%)]\tLoss: 0.140314\n",
      "Train Epoch: 32 [280/320 (88%)]\tLoss: 0.092640\n",
      "\n",
      "Test set: Accuracy: 26/80 (32%)\n",
      "\n",
      "training epoch 33\n",
      "Train Epoch: 33 [0/320 (0%)]\tLoss: 0.063985\n",
      "Train Epoch: 33 [40/320 (12%)]\tLoss: 0.093553\n",
      "Train Epoch: 33 [80/320 (25%)]\tLoss: 0.162095\n",
      "Train Epoch: 33 [120/320 (38%)]\tLoss: 0.073497\n",
      "Train Epoch: 33 [160/320 (50%)]\tLoss: 0.080685\n",
      "Train Epoch: 33 [200/320 (62%)]\tLoss: 0.156388\n",
      "Train Epoch: 33 [240/320 (75%)]\tLoss: 0.103222\n",
      "Train Epoch: 33 [280/320 (88%)]\tLoss: 0.114256\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 34\n",
      "Train Epoch: 34 [0/320 (0%)]\tLoss: 0.180098\n",
      "Train Epoch: 34 [40/320 (12%)]\tLoss: 0.118888\n",
      "Train Epoch: 34 [80/320 (25%)]\tLoss: 0.105681\n",
      "Train Epoch: 34 [120/320 (38%)]\tLoss: 0.134795\n",
      "Train Epoch: 34 [160/320 (50%)]\tLoss: 0.085446\n",
      "Train Epoch: 34 [200/320 (62%)]\tLoss: 0.120967\n",
      "Train Epoch: 34 [240/320 (75%)]\tLoss: 0.086351\n",
      "Train Epoch: 34 [280/320 (88%)]\tLoss: 0.060270\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 35\n",
      "Train Epoch: 35 [0/320 (0%)]\tLoss: 0.119876\n",
      "Train Epoch: 35 [40/320 (12%)]\tLoss: 0.107494\n",
      "Train Epoch: 35 [80/320 (25%)]\tLoss: 0.127480\n",
      "Train Epoch: 35 [120/320 (38%)]\tLoss: 0.133158\n",
      "Train Epoch: 35 [160/320 (50%)]\tLoss: 0.083494\n",
      "Train Epoch: 35 [200/320 (62%)]\tLoss: 0.068871\n",
      "Train Epoch: 35 [240/320 (75%)]\tLoss: 0.093150\n",
      "Train Epoch: 35 [280/320 (88%)]\tLoss: 0.093793\n",
      "\n",
      "Test set: Accuracy: 23/80 (29%)\n",
      "\n",
      "training epoch 36\n",
      "Train Epoch: 36 [0/320 (0%)]\tLoss: 0.099313\n",
      "Train Epoch: 36 [40/320 (12%)]\tLoss: 0.132149\n",
      "Train Epoch: 36 [80/320 (25%)]\tLoss: 0.078016\n",
      "Train Epoch: 36 [120/320 (38%)]\tLoss: 0.123311\n",
      "Train Epoch: 36 [160/320 (50%)]\tLoss: 0.082142\n",
      "Train Epoch: 36 [200/320 (62%)]\tLoss: 0.075490\n",
      "Train Epoch: 36 [240/320 (75%)]\tLoss: 0.115610\n",
      "Train Epoch: 36 [280/320 (88%)]\tLoss: 0.138755\n",
      "\n",
      "Test set: Accuracy: 29/80 (36%)\n",
      "\n",
      "training epoch 37\n",
      "Train Epoch: 37 [0/320 (0%)]\tLoss: 0.088953\n",
      "Train Epoch: 37 [40/320 (12%)]\tLoss: 0.155244\n",
      "Train Epoch: 37 [80/320 (25%)]\tLoss: 0.096527\n",
      "Train Epoch: 37 [120/320 (38%)]\tLoss: 0.067456\n",
      "Train Epoch: 37 [160/320 (50%)]\tLoss: 0.087665\n",
      "Train Epoch: 37 [200/320 (62%)]\tLoss: 0.095266\n",
      "Train Epoch: 37 [240/320 (75%)]\tLoss: 0.093823\n",
      "Train Epoch: 37 [280/320 (88%)]\tLoss: 0.086571\n",
      "\n",
      "Test set: Accuracy: 25/80 (31%)\n",
      "\n",
      "training epoch 38\n",
      "Train Epoch: 38 [0/320 (0%)]\tLoss: 0.088359\n",
      "Train Epoch: 38 [40/320 (12%)]\tLoss: 0.080159\n",
      "Train Epoch: 38 [80/320 (25%)]\tLoss: 0.103364\n",
      "Train Epoch: 38 [120/320 (38%)]\tLoss: 0.081327\n",
      "Train Epoch: 38 [160/320 (50%)]\tLoss: 0.074994\n",
      "Train Epoch: 38 [200/320 (62%)]\tLoss: 0.106419\n",
      "Train Epoch: 38 [240/320 (75%)]\tLoss: 0.100416\n",
      "Train Epoch: 38 [280/320 (88%)]\tLoss: 0.122042\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 39\n",
      "Train Epoch: 39 [0/320 (0%)]\tLoss: 0.066890\n",
      "Train Epoch: 39 [40/320 (12%)]\tLoss: 0.076454\n",
      "Train Epoch: 39 [80/320 (25%)]\tLoss: 0.103561\n",
      "Train Epoch: 39 [120/320 (38%)]\tLoss: 0.091741\n",
      "Train Epoch: 39 [160/320 (50%)]\tLoss: 0.208292\n",
      "Train Epoch: 39 [200/320 (62%)]\tLoss: 0.063992\n",
      "Train Epoch: 39 [240/320 (75%)]\tLoss: 0.101293\n",
      "Train Epoch: 39 [280/320 (88%)]\tLoss: 0.085218\n",
      "\n",
      "Test set: Accuracy: 25/80 (31%)\n",
      "\n",
      "training epoch 40\n",
      "Train Epoch: 40 [0/320 (0%)]\tLoss: 0.108266\n",
      "Train Epoch: 40 [40/320 (12%)]\tLoss: 0.065104\n",
      "Train Epoch: 40 [80/320 (25%)]\tLoss: 0.110390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [120/320 (38%)]\tLoss: 0.133885\n",
      "Train Epoch: 40 [160/320 (50%)]\tLoss: 0.145604\n",
      "Train Epoch: 40 [200/320 (62%)]\tLoss: 0.060129\n",
      "Train Epoch: 40 [240/320 (75%)]\tLoss: 0.087228\n",
      "Train Epoch: 40 [280/320 (88%)]\tLoss: 0.111683\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#W/ CACHING\n",
    "import warnings\n",
    "\n",
    "log_interval = 5\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for epoch in range(1, 41):\n",
    "    print(\"training epoch \" + str(epoch))\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "#     scheduler.step()\n",
    "    train(model, epoch)\n",
    "    scheduler.step()\n",
    "    test(model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1\n",
      "Train Epoch: 1 [0/320 (0%)]\tLoss: 0.238086\n",
      "Train Epoch: 1 [40/320 (12%)]\tLoss: 0.543195\n",
      "Train Epoch: 1 [80/320 (25%)]\tLoss: 0.277862\n",
      "Train Epoch: 1 [120/320 (38%)]\tLoss: 0.275000\n",
      "Train Epoch: 1 [160/320 (50%)]\tLoss: 0.128894\n",
      "Train Epoch: 1 [200/320 (62%)]\tLoss: 0.191396\n",
      "Train Epoch: 1 [240/320 (75%)]\tLoss: 0.220283\n",
      "Train Epoch: 1 [280/320 (88%)]\tLoss: 0.195243\n",
      "\n",
      "Test set: Accuracy: 21/80 (26%)\n",
      "\n",
      "training epoch 2\n",
      "Train Epoch: 2 [0/320 (0%)]\tLoss: 0.170415\n",
      "Train Epoch: 2 [40/320 (12%)]\tLoss: 0.197089\n",
      "Train Epoch: 2 [80/320 (25%)]\tLoss: 0.203403\n",
      "Train Epoch: 2 [120/320 (38%)]\tLoss: 0.202500\n",
      "Train Epoch: 2 [160/320 (50%)]\tLoss: 0.189248\n",
      "Train Epoch: 2 [200/320 (62%)]\tLoss: 0.190571\n",
      "Train Epoch: 2 [240/320 (75%)]\tLoss: 0.205890\n",
      "Train Epoch: 2 [280/320 (88%)]\tLoss: 0.166318\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 3\n",
      "Train Epoch: 3 [0/320 (0%)]\tLoss: 0.150036\n",
      "Train Epoch: 3 [40/320 (12%)]\tLoss: 0.133074\n",
      "Train Epoch: 3 [80/320 (25%)]\tLoss: 0.141485\n",
      "Train Epoch: 3 [120/320 (38%)]\tLoss: 0.186608\n",
      "Train Epoch: 3 [160/320 (50%)]\tLoss: 0.174406\n",
      "Train Epoch: 3 [200/320 (62%)]\tLoss: 0.170449\n",
      "Train Epoch: 3 [240/320 (75%)]\tLoss: 0.207569\n",
      "Train Epoch: 3 [280/320 (88%)]\tLoss: 0.147904\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 4\n",
      "Train Epoch: 4 [0/320 (0%)]\tLoss: 0.154219\n",
      "Train Epoch: 4 [40/320 (12%)]\tLoss: 0.158806\n",
      "Train Epoch: 4 [80/320 (25%)]\tLoss: 0.156023\n",
      "Train Epoch: 4 [120/320 (38%)]\tLoss: 0.142820\n",
      "Train Epoch: 4 [160/320 (50%)]\tLoss: 0.131893\n",
      "Train Epoch: 4 [200/320 (62%)]\tLoss: 0.139679\n",
      "Train Epoch: 4 [240/320 (75%)]\tLoss: 0.166096\n",
      "Train Epoch: 4 [280/320 (88%)]\tLoss: 0.149600\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 5\n",
      "Train Epoch: 5 [0/320 (0%)]\tLoss: 0.164960\n",
      "Train Epoch: 5 [40/320 (12%)]\tLoss: 0.145892\n",
      "Train Epoch: 5 [80/320 (25%)]\tLoss: 0.130076\n",
      "Train Epoch: 5 [120/320 (38%)]\tLoss: 0.225643\n",
      "Train Epoch: 5 [160/320 (50%)]\tLoss: 0.138466\n",
      "Train Epoch: 5 [200/320 (62%)]\tLoss: 0.122993\n",
      "Train Epoch: 5 [240/320 (75%)]\tLoss: 0.172815\n",
      "Train Epoch: 5 [280/320 (88%)]\tLoss: 0.146358\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 6\n",
      "Train Epoch: 6 [0/320 (0%)]\tLoss: 0.182183\n",
      "Train Epoch: 6 [40/320 (12%)]\tLoss: 0.169643\n",
      "Train Epoch: 6 [80/320 (25%)]\tLoss: 0.174136\n",
      "Train Epoch: 6 [120/320 (38%)]\tLoss: 0.139435\n",
      "Train Epoch: 6 [160/320 (50%)]\tLoss: 0.136533\n",
      "Train Epoch: 6 [200/320 (62%)]\tLoss: 0.108325\n",
      "Train Epoch: 6 [240/320 (75%)]\tLoss: 0.151947\n",
      "Train Epoch: 6 [280/320 (88%)]\tLoss: 0.147493\n",
      "\n",
      "Test set: Accuracy: 25/80 (31%)\n",
      "\n",
      "training epoch 7\n",
      "Train Epoch: 7 [0/320 (0%)]\tLoss: 0.157394\n",
      "Train Epoch: 7 [40/320 (12%)]\tLoss: 0.127231\n",
      "Train Epoch: 7 [80/320 (25%)]\tLoss: 0.154646\n",
      "Train Epoch: 7 [120/320 (38%)]\tLoss: 0.149551\n",
      "Train Epoch: 7 [160/320 (50%)]\tLoss: 0.151091\n",
      "Train Epoch: 7 [200/320 (62%)]\tLoss: 0.177884\n",
      "Train Epoch: 7 [240/320 (75%)]\tLoss: 0.143260\n",
      "Train Epoch: 7 [280/320 (88%)]\tLoss: 0.149940\n",
      "\n",
      "Test set: Accuracy: 30/80 (38%)\n",
      "\n",
      "training epoch 8\n",
      "Train Epoch: 8 [0/320 (0%)]\tLoss: 0.151844\n",
      "Train Epoch: 8 [40/320 (12%)]\tLoss: 0.159664\n",
      "Train Epoch: 8 [80/320 (25%)]\tLoss: 0.128205\n",
      "Train Epoch: 8 [120/320 (38%)]\tLoss: 0.195776\n",
      "Train Epoch: 8 [160/320 (50%)]\tLoss: 0.131025\n",
      "Train Epoch: 8 [200/320 (62%)]\tLoss: 0.152956\n",
      "Train Epoch: 8 [240/320 (75%)]\tLoss: 0.179723\n",
      "Train Epoch: 8 [280/320 (88%)]\tLoss: 0.139764\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 9\n",
      "Train Epoch: 9 [0/320 (0%)]\tLoss: 0.140411\n",
      "Train Epoch: 9 [40/320 (12%)]\tLoss: 0.136212\n",
      "Train Epoch: 9 [80/320 (25%)]\tLoss: 0.179193\n",
      "Train Epoch: 9 [120/320 (38%)]\tLoss: 0.119092\n",
      "Train Epoch: 9 [160/320 (50%)]\tLoss: 0.193237\n",
      "Train Epoch: 9 [200/320 (62%)]\tLoss: 0.138030\n",
      "Train Epoch: 9 [240/320 (75%)]\tLoss: 0.223285\n",
      "Train Epoch: 9 [280/320 (88%)]\tLoss: 0.147284\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 10\n",
      "Train Epoch: 10 [0/320 (0%)]\tLoss: 0.119645\n",
      "Train Epoch: 10 [40/320 (12%)]\tLoss: 0.114722\n",
      "Train Epoch: 10 [80/320 (25%)]\tLoss: 0.154636\n",
      "Train Epoch: 10 [120/320 (38%)]\tLoss: 0.165610\n",
      "Train Epoch: 10 [160/320 (50%)]\tLoss: 0.163765\n",
      "Train Epoch: 10 [200/320 (62%)]\tLoss: 0.164531\n",
      "Train Epoch: 10 [240/320 (75%)]\tLoss: 0.115436\n",
      "Train Epoch: 10 [280/320 (88%)]\tLoss: 0.159676\n",
      "\n",
      "Test set: Accuracy: 26/80 (32%)\n",
      "\n",
      "training epoch 11\n",
      "Train Epoch: 11 [0/320 (0%)]\tLoss: 0.129056\n",
      "Train Epoch: 11 [40/320 (12%)]\tLoss: 0.105648\n",
      "Train Epoch: 11 [80/320 (25%)]\tLoss: 0.139317\n",
      "Train Epoch: 11 [120/320 (38%)]\tLoss: 0.120449\n",
      "Train Epoch: 11 [160/320 (50%)]\tLoss: 0.156765\n",
      "Train Epoch: 11 [200/320 (62%)]\tLoss: 0.121326\n",
      "Train Epoch: 11 [240/320 (75%)]\tLoss: 0.148824\n",
      "Train Epoch: 11 [280/320 (88%)]\tLoss: 0.133836\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 12\n",
      "Train Epoch: 12 [0/320 (0%)]\tLoss: 0.167767\n",
      "Train Epoch: 12 [40/320 (12%)]\tLoss: 0.099086\n",
      "Train Epoch: 12 [80/320 (25%)]\tLoss: 0.167303\n",
      "Train Epoch: 12 [120/320 (38%)]\tLoss: 0.144167\n",
      "Train Epoch: 12 [160/320 (50%)]\tLoss: 0.109036\n",
      "Train Epoch: 12 [200/320 (62%)]\tLoss: 0.121921\n",
      "Train Epoch: 12 [240/320 (75%)]\tLoss: 0.155197\n",
      "Train Epoch: 12 [280/320 (88%)]\tLoss: 0.094654\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 13\n",
      "Train Epoch: 13 [0/320 (0%)]\tLoss: 0.112444\n",
      "Train Epoch: 13 [40/320 (12%)]\tLoss: 0.143936\n",
      "Train Epoch: 13 [80/320 (25%)]\tLoss: 0.155205\n",
      "Train Epoch: 13 [120/320 (38%)]\tLoss: 0.123804\n",
      "Train Epoch: 13 [160/320 (50%)]\tLoss: 0.142318\n",
      "Train Epoch: 13 [200/320 (62%)]\tLoss: 0.117651\n",
      "Train Epoch: 13 [240/320 (75%)]\tLoss: 0.159394\n",
      "Train Epoch: 13 [280/320 (88%)]\tLoss: 0.169772\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 14\n",
      "Train Epoch: 14 [0/320 (0%)]\tLoss: 0.103349\n",
      "Train Epoch: 14 [40/320 (12%)]\tLoss: 0.116250\n",
      "Train Epoch: 14 [80/320 (25%)]\tLoss: 0.114624\n",
      "Train Epoch: 14 [120/320 (38%)]\tLoss: 0.113438\n",
      "Train Epoch: 14 [160/320 (50%)]\tLoss: 0.146591\n",
      "Train Epoch: 14 [200/320 (62%)]\tLoss: 0.149064\n",
      "Train Epoch: 14 [240/320 (75%)]\tLoss: 0.117036\n",
      "Train Epoch: 14 [280/320 (88%)]\tLoss: 0.138983\n",
      "\n",
      "Test set: Accuracy: 21/80 (26%)\n",
      "\n",
      "training epoch 15\n",
      "Train Epoch: 15 [0/320 (0%)]\tLoss: 0.148391\n",
      "Train Epoch: 15 [40/320 (12%)]\tLoss: 0.138657\n",
      "Train Epoch: 15 [80/320 (25%)]\tLoss: 0.162175\n",
      "Train Epoch: 15 [120/320 (38%)]\tLoss: 0.141677\n",
      "Train Epoch: 15 [160/320 (50%)]\tLoss: 0.083069\n",
      "Train Epoch: 15 [200/320 (62%)]\tLoss: 0.153043\n",
      "Train Epoch: 15 [240/320 (75%)]\tLoss: 0.094199\n",
      "Train Epoch: 15 [280/320 (88%)]\tLoss: 0.152439\n",
      "\n",
      "Test set: Accuracy: 27/80 (34%)\n",
      "\n",
      "training epoch 16\n",
      "Train Epoch: 16 [0/320 (0%)]\tLoss: 0.165920\n",
      "Train Epoch: 16 [40/320 (12%)]\tLoss: 0.138766\n",
      "Train Epoch: 16 [80/320 (25%)]\tLoss: 0.177793\n",
      "Train Epoch: 16 [120/320 (38%)]\tLoss: 0.140460\n",
      "Train Epoch: 16 [160/320 (50%)]\tLoss: 0.140156\n",
      "Train Epoch: 16 [200/320 (62%)]\tLoss: 0.106299\n",
      "Train Epoch: 16 [240/320 (75%)]\tLoss: 0.153657\n",
      "Train Epoch: 16 [280/320 (88%)]\tLoss: 0.103858\n",
      "\n",
      "Test set: Accuracy: 11/80 (14%)\n",
      "\n",
      "training epoch 17\n",
      "Train Epoch: 17 [0/320 (0%)]\tLoss: 0.152024\n",
      "Train Epoch: 17 [40/320 (12%)]\tLoss: 0.139205\n",
      "Train Epoch: 17 [80/320 (25%)]\tLoss: 0.139676\n",
      "Train Epoch: 17 [120/320 (38%)]\tLoss: 0.089222\n",
      "Train Epoch: 17 [160/320 (50%)]\tLoss: 0.102650\n",
      "Train Epoch: 17 [200/320 (62%)]\tLoss: 0.149349\n",
      "Train Epoch: 17 [240/320 (75%)]\tLoss: 0.120480\n",
      "Train Epoch: 17 [280/320 (88%)]\tLoss: 0.192999\n",
      "\n",
      "Test set: Accuracy: 25/80 (31%)\n",
      "\n",
      "training epoch 18\n",
      "Train Epoch: 18 [0/320 (0%)]\tLoss: 0.117098\n",
      "Train Epoch: 18 [40/320 (12%)]\tLoss: 0.150689\n",
      "Train Epoch: 18 [80/320 (25%)]\tLoss: 0.110619\n",
      "Train Epoch: 18 [120/320 (38%)]\tLoss: 0.126405\n",
      "Train Epoch: 18 [160/320 (50%)]\tLoss: 0.177496\n",
      "Train Epoch: 18 [200/320 (62%)]\tLoss: 0.149360\n",
      "Train Epoch: 18 [240/320 (75%)]\tLoss: 0.158848\n",
      "Train Epoch: 18 [280/320 (88%)]\tLoss: 0.147620\n",
      "\n",
      "Test set: Accuracy: 17/80 (21%)\n",
      "\n",
      "training epoch 19\n",
      "Train Epoch: 19 [0/320 (0%)]\tLoss: 0.088324\n",
      "Train Epoch: 19 [40/320 (12%)]\tLoss: 0.163841\n",
      "Train Epoch: 19 [80/320 (25%)]\tLoss: 0.097446\n",
      "Train Epoch: 19 [120/320 (38%)]\tLoss: 0.155972\n",
      "Train Epoch: 19 [160/320 (50%)]\tLoss: 0.181698\n",
      "Train Epoch: 19 [200/320 (62%)]\tLoss: 0.145539\n",
      "Train Epoch: 19 [240/320 (75%)]\tLoss: 0.120354\n",
      "Train Epoch: 19 [280/320 (88%)]\tLoss: 0.077258\n",
      "\n",
      "Test set: Accuracy: 28/80 (35%)\n",
      "\n",
      "training epoch 20\n",
      "Train Epoch: 20 [0/320 (0%)]\tLoss: 0.150226\n",
      "Train Epoch: 20 [40/320 (12%)]\tLoss: 0.153854\n",
      "Train Epoch: 20 [80/320 (25%)]\tLoss: 0.128766\n",
      "Train Epoch: 20 [120/320 (38%)]\tLoss: 0.100924\n",
      "Train Epoch: 20 [160/320 (50%)]\tLoss: 0.139254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [200/320 (62%)]\tLoss: 0.127817\n",
      "Train Epoch: 20 [240/320 (75%)]\tLoss: 0.105206\n",
      "Train Epoch: 20 [280/320 (88%)]\tLoss: 0.118119\n",
      "\n",
      "Test set: Accuracy: 24/80 (30%)\n",
      "\n",
      "training epoch 21\n",
      "Train Epoch: 21 [0/320 (0%)]\tLoss: 0.120037\n",
      "Train Epoch: 21 [40/320 (12%)]\tLoss: 0.187839\n",
      "Train Epoch: 21 [80/320 (25%)]\tLoss: 0.096697\n",
      "Train Epoch: 21 [120/320 (38%)]\tLoss: 0.168122\n",
      "Train Epoch: 21 [160/320 (50%)]\tLoss: 0.106986\n",
      "Train Epoch: 21 [200/320 (62%)]\tLoss: 0.132516\n",
      "Train Epoch: 21 [240/320 (75%)]\tLoss: 0.094457\n",
      "Train Epoch: 21 [280/320 (88%)]\tLoss: 0.115992\n",
      "\n",
      "Test set: Accuracy: 19/80 (24%)\n",
      "\n",
      "training epoch 22\n",
      "Train Epoch: 22 [0/320 (0%)]\tLoss: 0.114777\n",
      "Train Epoch: 22 [40/320 (12%)]\tLoss: 0.126823\n",
      "Train Epoch: 22 [80/320 (25%)]\tLoss: 0.130811\n",
      "Train Epoch: 22 [120/320 (38%)]\tLoss: 0.103881\n",
      "Train Epoch: 22 [160/320 (50%)]\tLoss: 0.136740\n",
      "Train Epoch: 22 [200/320 (62%)]\tLoss: 0.145961\n",
      "Train Epoch: 22 [240/320 (75%)]\tLoss: 0.172568\n",
      "Train Epoch: 22 [280/320 (88%)]\tLoss: 0.130506\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 23\n",
      "Train Epoch: 23 [0/320 (0%)]\tLoss: 0.100821\n",
      "Train Epoch: 23 [40/320 (12%)]\tLoss: 0.134531\n",
      "Train Epoch: 23 [80/320 (25%)]\tLoss: 0.131107\n",
      "Train Epoch: 23 [120/320 (38%)]\tLoss: 0.136765\n",
      "Train Epoch: 23 [160/320 (50%)]\tLoss: 0.118235\n",
      "Train Epoch: 23 [200/320 (62%)]\tLoss: 0.073518\n",
      "Train Epoch: 23 [240/320 (75%)]\tLoss: 0.126337\n",
      "Train Epoch: 23 [280/320 (88%)]\tLoss: 0.081607\n",
      "\n",
      "Test set: Accuracy: 17/80 (21%)\n",
      "\n",
      "training epoch 24\n",
      "Train Epoch: 24 [0/320 (0%)]\tLoss: 0.124856\n",
      "Train Epoch: 24 [40/320 (12%)]\tLoss: 0.098437\n",
      "Train Epoch: 24 [80/320 (25%)]\tLoss: 0.085299\n",
      "Train Epoch: 24 [120/320 (38%)]\tLoss: 0.076571\n",
      "Train Epoch: 24 [160/320 (50%)]\tLoss: 0.105946\n",
      "Train Epoch: 24 [200/320 (62%)]\tLoss: 0.086284\n",
      "Train Epoch: 24 [240/320 (75%)]\tLoss: 0.131291\n",
      "Train Epoch: 24 [280/320 (88%)]\tLoss: 0.150590\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 25\n",
      "Train Epoch: 25 [0/320 (0%)]\tLoss: 0.063574\n",
      "Train Epoch: 25 [40/320 (12%)]\tLoss: 0.131945\n",
      "Train Epoch: 25 [80/320 (25%)]\tLoss: 0.121437\n",
      "Train Epoch: 25 [120/320 (38%)]\tLoss: 0.087633\n",
      "Train Epoch: 25 [160/320 (50%)]\tLoss: 0.092423\n",
      "Train Epoch: 25 [200/320 (62%)]\tLoss: 0.134005\n",
      "Train Epoch: 25 [240/320 (75%)]\tLoss: 0.086463\n",
      "Train Epoch: 25 [280/320 (88%)]\tLoss: 0.203147\n",
      "\n",
      "Test set: Accuracy: 17/80 (21%)\n",
      "\n",
      "training epoch 26\n",
      "Train Epoch: 26 [0/320 (0%)]\tLoss: 0.101273\n",
      "Train Epoch: 26 [40/320 (12%)]\tLoss: 0.095004\n",
      "Train Epoch: 26 [80/320 (25%)]\tLoss: 0.124726\n",
      "Train Epoch: 26 [120/320 (38%)]\tLoss: 0.080743\n",
      "Train Epoch: 26 [160/320 (50%)]\tLoss: 0.131130\n",
      "Train Epoch: 26 [200/320 (62%)]\tLoss: 0.119825\n",
      "Train Epoch: 26 [240/320 (75%)]\tLoss: 0.149562\n",
      "Train Epoch: 26 [280/320 (88%)]\tLoss: 0.055436\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 27\n",
      "Train Epoch: 27 [0/320 (0%)]\tLoss: 0.093105\n",
      "Train Epoch: 27 [40/320 (12%)]\tLoss: 0.142004\n",
      "Train Epoch: 27 [80/320 (25%)]\tLoss: 0.110867\n",
      "Train Epoch: 27 [120/320 (38%)]\tLoss: 0.092529\n",
      "Train Epoch: 27 [160/320 (50%)]\tLoss: 0.119568\n",
      "Train Epoch: 27 [200/320 (62%)]\tLoss: 0.123875\n",
      "Train Epoch: 27 [240/320 (75%)]\tLoss: 0.107157\n",
      "Train Epoch: 27 [280/320 (88%)]\tLoss: 0.124114\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 28\n",
      "Train Epoch: 28 [0/320 (0%)]\tLoss: 0.119543\n",
      "Train Epoch: 28 [40/320 (12%)]\tLoss: 0.093044\n",
      "Train Epoch: 28 [80/320 (25%)]\tLoss: 0.105645\n",
      "Train Epoch: 28 [120/320 (38%)]\tLoss: 0.123448\n",
      "Train Epoch: 28 [160/320 (50%)]\tLoss: 0.129895\n",
      "Train Epoch: 28 [200/320 (62%)]\tLoss: 0.087102\n",
      "Train Epoch: 28 [240/320 (75%)]\tLoss: 0.077670\n",
      "Train Epoch: 28 [280/320 (88%)]\tLoss: 0.121020\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 29\n",
      "Train Epoch: 29 [0/320 (0%)]\tLoss: 0.072102\n",
      "Train Epoch: 29 [40/320 (12%)]\tLoss: 0.114690\n",
      "Train Epoch: 29 [80/320 (25%)]\tLoss: 0.095350\n",
      "Train Epoch: 29 [120/320 (38%)]\tLoss: 0.138868\n",
      "Train Epoch: 29 [160/320 (50%)]\tLoss: 0.120218\n",
      "Train Epoch: 29 [200/320 (62%)]\tLoss: 0.127246\n",
      "Train Epoch: 29 [240/320 (75%)]\tLoss: 0.117928\n",
      "Train Epoch: 29 [280/320 (88%)]\tLoss: 0.159421\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 30\n",
      "Train Epoch: 30 [0/320 (0%)]\tLoss: 0.148450\n",
      "Train Epoch: 30 [40/320 (12%)]\tLoss: 0.087200\n",
      "Train Epoch: 30 [80/320 (25%)]\tLoss: 0.100828\n",
      "Train Epoch: 30 [120/320 (38%)]\tLoss: 0.094036\n",
      "Train Epoch: 30 [160/320 (50%)]\tLoss: 0.089926\n",
      "Train Epoch: 30 [200/320 (62%)]\tLoss: 0.123016\n",
      "Train Epoch: 30 [240/320 (75%)]\tLoss: 0.126183\n",
      "Train Epoch: 30 [280/320 (88%)]\tLoss: 0.107396\n",
      "\n",
      "Test set: Accuracy: 19/80 (24%)\n",
      "\n",
      "training epoch 31\n",
      "First round of training complete. Setting learn rate to 0.001.\n",
      "Train Epoch: 31 [0/320 (0%)]\tLoss: 0.083259\n",
      "Train Epoch: 31 [40/320 (12%)]\tLoss: 0.062693\n",
      "Train Epoch: 31 [80/320 (25%)]\tLoss: 0.078890\n",
      "Train Epoch: 31 [120/320 (38%)]\tLoss: 0.097783\n",
      "Train Epoch: 31 [160/320 (50%)]\tLoss: 0.088833\n",
      "Train Epoch: 31 [200/320 (62%)]\tLoss: 0.113451\n",
      "Train Epoch: 31 [240/320 (75%)]\tLoss: 0.130477\n",
      "Train Epoch: 31 [280/320 (88%)]\tLoss: 0.106659\n",
      "\n",
      "Test set: Accuracy: 18/80 (22%)\n",
      "\n",
      "training epoch 32\n",
      "Train Epoch: 32 [0/320 (0%)]\tLoss: 0.143122\n",
      "Train Epoch: 32 [40/320 (12%)]\tLoss: 0.107261\n",
      "Train Epoch: 32 [80/320 (25%)]\tLoss: 0.104706\n",
      "Train Epoch: 32 [120/320 (38%)]\tLoss: 0.094063\n",
      "Train Epoch: 32 [160/320 (50%)]\tLoss: 0.086028\n",
      "Train Epoch: 32 [200/320 (62%)]\tLoss: 0.146258\n",
      "Train Epoch: 32 [240/320 (75%)]\tLoss: 0.153469\n",
      "Train Epoch: 32 [280/320 (88%)]\tLoss: 0.089463\n",
      "\n",
      "Test set: Accuracy: 20/80 (25%)\n",
      "\n",
      "training epoch 33\n",
      "Train Epoch: 33 [0/320 (0%)]\tLoss: 0.117592\n",
      "Train Epoch: 33 [40/320 (12%)]\tLoss: 0.102590\n",
      "Train Epoch: 33 [80/320 (25%)]\tLoss: 0.111098\n"
     ]
    }
   ],
   "source": [
    "#ORIGINAL\n",
    "import warnings\n",
    "\n",
    "log_interval = 5\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for epoch in range(1, 41):\n",
    "    print(\"training epoch \" + str(epoch))\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "#     scheduler.step()\n",
    "    train(model, epoch)\n",
    "    scheduler.step()\n",
    "    test(model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "\n",
    "below is the mfccs notes / random code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "torch.save(model.state_dict(), 'dataset_model_soundemotion.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio, sample_rate = librosa.load(\"SongEmotionDataset/1.mp3\", res_type='kaiser_fast')\n",
    "# # [print(x) for x in audio]\n",
    "\n",
    "# #convert audio into 2d array\n",
    "# mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "# # mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "# print(mfccs.shape, audio.shape)\n",
    "# mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_tensor = torch.tensor(audio)\n",
    "# audio_tensor\n",
    "# audio_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sound_file in data_path.iterdir():\n",
    "#     if \".mp3\" in str(sound_file):\n",
    "#         print(sound_file)\n",
    "#         audio, sample_rate = librosa.load(str(sound_file), res_type='kaiser_fast')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
